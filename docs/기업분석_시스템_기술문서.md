# 기업 분석 시스템 기술 문서

> **문서 버전**: v4.0  
> **최종 수정일**: 2026-02-27  
> **대상**: 내부 기술 리뷰용

---

## 목차

1. [시스템 개요](#1-시스템-개요)
2. [아키텍처 전체 흐름](#2-아키텍처-전체-흐름)
3. [API 엔드포인트 (진입점)](#3-api-엔드포인트-진입점)
4. [페르소나 정의 및 검색 키워드](#4-페르소나-정의-및-검색-키워드)
5. [파이프라인 상세 (Sequential RAG 3-Phase)](#5-파이프라인-상세-sequential-rag-3-phase)
6. [검색 시스템 (HybridRM)](#6-검색-시스템-hybridrm)
7. [중간 정제 파이프라인 (Intermediate Refinement)](#7-중간-정제-파이프라인-intermediate-refinement)
8. [SWOT 마이크로 에이전트 시스템](#8-swot-마이크로-에이전트-시스템)
9. [NLI 팩트체크 검증 루프](#9-nli-팩트체크-검증-루프)
10. [LLM Resilience 시스템](#10-llm-resilience-시스템)
11. [최종 출력 스키마](#11-최종-출력-스키마)
12. [프롬프트 설계 전문](#12-프롬프트-설계-전문)
13. [파일 구조 맵](#13-파일-구조-맵)

---

## 1. 시스템 개요

My Career AI의 기업 분석 시스템은 **고정 페르소나 기반 Sequential RAG(Retrieval-Augmented Generation) 파이프라인**으로 동작합니다.

### 핵심 설계 원칙

| 원칙 | 설명 |
|------|------|
| **고정 페르소나** | 3명의 고정 전문가(산업 애널리스트, 수석 취업 지원관, 실무 면접관)가 각각의 관점에서 데이터를 수집 |
| **Sequential RAG** | 3개 Phase를 순차 실행하며, 이전 Phase의 검증 결과를 다음 Phase에 체이닝(주입) |
| **마이크로 에이전트** | Phase 2(SWOT)는 5개 독립 에이전트로 분할하여 병렬 실행 후 무손실 병합 |
| **NLI 팩트체크** | 각 Phase 생성 후 Evaluator(심사관) + Refiner(교정관) 루프로 환각 검증/교정 |
| **Graceful Degradation** | 개별 Phase나 에이전트 실패 시 해당 섹션만 기본값 처리, 전체 파이프라인은 계속 진행 |

### 기술 스택

- **Backend**: FastAPI (Python 3.11, async/await)
- **LLM**: OpenAI GPT-4o / GPT-4o-mini, Google Gemini 2.0 Flash (litellm 통합)
- **검색**: Serper API (Google 검색) + PostgreSQL pgvector (내부 벡터 검색)
- **DB**: PostgreSQL 15 + pgvector, SQLAlchemy 2.0 (비동기)
- **스키마 검증**: Pydantic V2 (JSON 출력 SSOT)

---

## 2. 아키텍처 전체 흐름

```
사용자 요청 (프론트엔드)
    |
    v
[POST /api/generate]  ─── router.py
    |
    v
[StormService.create_job()]  ─── Job 생성 (DB + 메모리)
    |
    v
[BackgroundTasks로 파이프라인 위임]
    |
    v
[StormService.run_pipeline()]
    |
    v
[run_career_pipeline()]  ─── career_pipeline.py (메인 오케스트레이터)
    |
    |── Phase 0: 초기화
    |   ├── DB에서 기업 정보 조회
    |   ├── HybridRM(검색 엔진) 생성
    |   └── 고정 쿼리 큐 생성 + 후처리
    |
    |── Phase 1: 기초 팩트 (company_overview)
    |   ├── 쿼리 확장 (QuestionToQuery)
    |   ├── HybridRM 검색 (내부 DB + 외부 Serper)
    |   ├── 중간 정제 (AnswerQuestion)
    |   ├── LLM 호출 (GPT-4o) → JSON 생성
    |   └── NLI 검증 루프 (Evaluator → Refiner)
    |
    |── Phase 2: 심층 분석 (corporate_culture + swot_analysis)
    |   ├── 쿼리 확장 + 검색 + 중간 정제
    |   ├── 5개 마이크로 에이전트 병렬 실행
    |   |   ├── Culture Agent
    |   |   ├── Strength Agent
    |   |   ├── Weakness Agent
    |   |   ├── Opportunity Agent
    |   |   └── Threat Agent
    |   ├── 코드 레벨 무손실 병합
    |   └── SO/WT 전략 경량 LLM 호출 (6번째)
    |
    |── Phase 3: 면접 파생 (interview_preparation)
    |   ├── Phase 1+2 검증 결과를 체이닝 컨텍스트로 주입
    |   ├── 쿼리 확장 + 검색 + 중간 정제
    |   ├── LLM 호출 → JSON 생성
    |   └── NLI 검증 루프
    |
    |── Phase 4: 결과 병합 (_merge_phase_results)
    |   └── 3개 Phase 부분 결과를 CareerAnalysisReport 1개로 통합
    |
    └── Phase 5: 저장
        ├── DB 저장 (generated_reports 테이블)
        ├── JSON 파일 저장 (results/ 디렉토리)
        ├── 검증 로그 저장
        └── JOBS 메모리 상태 업데이트 (완료)
```

### 진행률(Progress) 구간 배분

| 구간 | 진행률 | 내용 |
|------|--------|------|
| 초기화 | 0-15% | DB 조회, 쿼리 큐 생성, HybridRM 초기화 |
| Phase 1 | 15-35% | 기초 팩트 수집 및 검증 |
| Phase 2 | 35-60% | SWOT 마이크로 에이전트 병렬 실행 |
| Phase 3 | 60-80% | 면접 대비 파생 및 검증 |
| 병합/저장 | 80-100% | 결과 통합, DB 저장, 파일 기록 |

---

## 3. API 엔드포인트 (진입점)

### 리포트 생성 요청

```
POST /api/generate
```

**요청 본문**:

```json
{
    "company_name": "삼성전자",
    "topic": "기업 분석"
}
```

**처리 흐름**:

1. `StormService.create_job()` 호출 → DB에 Job 레코드 생성 (PENDING 상태)
2. 메모리 JOBS dict에 초기 상태 등록 (`progress: 0`)
3. `BackgroundTasks.add_task()`로 파이프라인을 비동기 백그라운드 실행
4. 클라이언트에게 `job_id` 즉시 반환

**응답**:

```json
{
    "id": "uuid-string",
    "status": "pending",
    "company_name": "삼성전자",
    "topic": "기업 분석"
}
```

### 작업 상태 폴링

```
GET /api/status/{job_id}
```

**응답**:

```json
{
    "job_id": "uuid-string",
    "status": "processing",
    "progress": 45,
    "message": "Phase 2: 마이크로 에이전트 병렬 실행 중",
    "report_id": null
}
```

- **1차 조회**: 메모리 JOBS dict (실시간 progress %)
- **2차 조회**: DB 폴백 (메모리에 없는 과거 Job)

---

## 4. 페르소나 정의 및 검색 키워드

### 4.1 페르소나 1: 산업 애널리스트 (Industry Analyst)

> **담당 Phase**: Phase 1 (기초 팩트)  
> **생성 섹션**: `company_overview`

**역할 정의**:

```
기업 개요 및 SWOT 분석 데이터 수집 담당 (객관적 지표, DART, 최신 경제 뉴스 기반)
```

**시스템 프롬프트 핵심 지침**:

- 위키백과, 개인 블로그 등 범용적/신뢰 불가 출처를 **철저히 배제**
- **DART(전자공시시스템), NICE평가정보, 주요 경제 언론사 기사만** 사용
- 모호한 서술형 피하고 **인과관계가 명확한 개조식(Bullet Point)** 작성
- 재무 데이터는 **직전 반기 이내 최신 자료** 원칙, **정확한 단위와 기준 연월** 명시

**검색 쿼리 큐 (Query Queue)**:

| # | 태그 | 검색 쿼리 템플릿 | 예시 (삼성전자) |
|---|------|-----------------|----------------|
| 1 | DART | `[DART] {company_name} 주요사업 및 시장점유율` | `삼성전자 주요사업 및 시장점유율` |
| 2 | DART | `[DART] {company_name} {year} 연결재무제표 매출액 영업이익` | `삼성전자 2025 연결재무제표 매출액 영업이익` |
| 3 | WEB | `[WEB] {company_name} 신규 진출 사업 및 투자 기사` | `삼성전자 신규 진출 사업 및 투자 기사` |
| 4 | WEB | `[WEB] {company_name} 외부 환경 위협 요인 원자재 규제` | `삼성전자 외부 환경 위협 요인 원자재 규제` |
| 5 | WEB | `[WEB] {company_name} 주요 경쟁사 실적 및 시장 순위 비교` | `삼성전자 주요 경쟁사 실적 및 시장 순위 비교` |

---

### 4.2 페르소나 2: 수석 취업 지원관 (Senior Career Advisor)

> **담당 Phase**: Phase 2 (심층 분석)  
> **생성 섹션**: `corporate_culture` + `swot_analysis`

**역할 정의**:

```
기업 문화 데이터 수집 담당 (핵심 가치, 인재상, 복리후생 등 구직자 맞춤형 연성 데이터 발굴)
```

**시스템 프롬프트 핵심 지침**:

- 기업 홈페이지 **형식적 홍보 문구를 넘어**, 실제 구직자에게 유용한 연성 데이터(Soft Data) 발굴
- **신년사, 기업 공식 블로그, 현직자 인터뷰 기사, 직장인 익명 커뮤니티 리뷰** 등 교차 검증
- 기업이 선호하는 **업무 방식과 조직문화적 특성**으로 가공하여 직관적 개조식 요약

**검색 쿼리 큐 (Query Queue)**:

| # | 태그 | 검색 쿼리 템플릿 | 예시 (삼성전자) |
|---|------|-----------------|----------------|
| 1 | WEB | `[WEB] {company_name} 공식 홈페이지 인재상 핵심가치` | `삼성전자 공식 홈페이지 인재상 핵심가치` |
| 2 | WEB | `[WEB] {company_name} 신년사 대표이사 강조 키워드` | `삼성전자 신년사 대표이사 강조 키워드` |
| 3 | WEB | `[WEB] {company_name} 조직문화 워라밸 후기 블라인드` | `삼성전자 조직문화 워라밸 후기 블라인드` |
| 4 | WEB | `[WEB] {company_name} 신입사원 교육 채용 블로그` | `삼성전자 신입사원 교육 채용 블로그` |
| 5 | WEB | `[WEB] {company_name} 독자적인 복리후생 및 근무제도` | `삼성전자 독자적인 복리후생 및 근무제도` |

---

### 4.3 페르소나 3: 실무 면접관 (Practical Interviewer)

> **담당 Phase**: Phase 3 (면접 파생)  
> **생성 섹션**: `interview_preparation`

**역할 정의**:

```
면접 대비 데이터 수집 담당 (최근 이슈, 약점 기반의 실전 압박 면접 질문 도출)
```

**시스템 프롬프트 핵심 지침**:

- 기업의 긍정적인 면뿐만 아니라 **부정적 이슈, 실적 하락 요인, 점유율 하락** 등 민감한 리스크 집중 탐색
- 단편적 부정적 정보 나열을 넘어, **지원자가 방어하고 해결책을 제시할 수 있는 실전 압박 면접용 질문** 형태로 가공
- **SWOT 약점/위협 항목과 1:1 매핑**되는 압박 질문 필수 생성

**검색 쿼리 큐 (Query Queue)**:

| # | 태그 | 검색 쿼리 템플릿 | 예시 (삼성전자) |
|---|------|-----------------|----------------|
| 1 | WEB | `[WEB] {company_name} 최근 논란 악재 리스크 뉴스` | `삼성전자 최근 논란 악재 리스크 뉴스` |
| 2 | DART | `[DART] {company_name} 영업이익 감소 실적 하락 원인` | `삼성전자 영업이익 감소 실적 하락 원인` |
| 3 | WEB | `[WEB] {company_name} 경쟁사 대비 약점 극복 전략` | `삼성전자 경쟁사 대비 약점 극복 전략` |
| 4 | WEB | `[WEB] {company_name} 직무 면접 기출문제 후기` | `삼성전자 직무 면접 기출문제 후기` |
| 5 | WEB | `[WEB] {company_name} 신사업 실패 철수 사례` | `삼성전자 신사업 실패 철수 사례` |

---

### 4.4 쿼리 후처리 규칙

`build_query_queue()` 함수가 생성한 원시 쿼리는 `_post_process_queries()`에서 다음 후처리를 거칩니다:

1. **기업명 Prefix**: 쿼리 앞에 기업명이 없으면 자동 추가
2. **PDF 차단**: `-filetype:pdf` 접미사 추가 (불필요한 PDF 결과 배제)
3. **DART 사이트 타겟팅**: `[DART]` 태그 쿼리에 `site:dart.fss.or.kr OR site:kind.krx.co.kr` 추가
4. **길이 제한**: 쿼리 200자 초과 시 절삭

---

## 5. 파이프라인 상세 (Sequential RAG 3-Phase)

### 5.1 Phase 1: 기초 팩트 (company_overview)

**담당 페르소나**: 산업 애널리스트  
**출력 섹션**: `company_overview` (기업 소개, 업종, 직원 수, 본사 위치, 재무 정보)

#### 실행 단계

```
1. 해당 Phase 페르소나 쿼리만 필터링 (5개)
       |
2. QuestionToQuery: 각 쿼리를 3~5개로 확장 (LLM: gpt-4o-mini)
   예: "삼성전자 주요사업 및 시장점유율"
       → "삼성전자 2026 시장점유율 반도체"
       → "삼성전자 주요 사업부문 매출 비중"
       → "삼성전자 DS IM CE 사업부 소개"
       |
3. HybridRM 검색: 확장된 쿼리마다 내부 DB + 외부 Serper 검색 실행
       |
4. 비동기 DB 적재: 검색 결과를 external_informations 테이블에 백그라운드 Upsert
       |
5. AnswerQuestion: 검색 결과를 경량 LLM(gpt-4o-mini)으로 1차 정제
   - 각 질문별 스니펫에서 핵심 답변 추출/압축 (300자 이내)
   - 병렬 실행 (asyncio.Semaphore로 동시 5개 제한)
       |
6. 정제된 답변 기반 LLM 컨텍스트 빌드
   - MAX_CONTEXT_CHARS(50,000자) 기반 Truncation 적용
       |
7. 최종 LLM 호출 (GPT-4o)
   - 시스템 프롬프트: Phase 1 전용 (company_overview 스키마만 포함)
   - JSON Object 모드 강제 (response_format: json_object)
   - 재시도 최대 3회 (파싱 실패 시 에러 피드백 포함 재프롬프트)
       |
8. NLI 검증 루프 (최대 2회)
   - Evaluator: 환각 탐지
   - Refiner: 자동 교정
   - 2회 후에도 환각 잔존 시 강제 삭제
```

#### Phase 1 시스템 프롬프트 핵심 규칙

- 재무 수치는 **DART 또는 KIND에서 확인된 직전 회계연도 확정 실적만** 사용
- 애널리스트 추정치, 컨센서스, 시장 전망치 등 **미래 예측 데이터를 확정 사실처럼 서술 금지**
- `introduction`: **5-10문장, 최소 200자 이상** 상세 기업 소개
- `financials`: **'N조N억원 / YYYY년 기준'** 형식 필수

---

### 5.2 Phase 2: 심층 분석 (corporate_culture + swot_analysis)

**담당 페르소나**: 수석 취업 지원관  
**출력 섹션**: `corporate_culture`, `swot_analysis`  
**특수 아키텍처**: 마이크로 에이전트 5병렬 실행 (상세는 [8장](#8-swot-마이크로-에이전트-시스템) 참조)

#### 체이닝(Chaining) 메커니즘

Phase 1에서 검증 완료된 `company_overview`를 Phase 2 프롬프트에 주입합니다:

```
## 이전 분석 단계 검증 결과
{Phase 1 검증 결과 JSON}
```

- **Context Starvation 방어**: Phase 1이 실패하면 `"이전 분석 단계에서 데이터 부족으로 검증된 데이터가 충분하지 않습니다. 본 단계에서는 검색 결과만을 기반으로 분석을 수행하십시오."` 메시지 주입
- **MAX_CHAINING_CHARS(30,000자)** 초과 시 배열 항목을 뒤에서부터 안전 절삭

#### Phase 2 시스템 프롬프트 핵심 규칙

**corporate_culture 필드별 규격**:

- `core_values`: 각 항목 **'가치명: 1-2문장 상세 설명'** 형식, 최소 3개, 각 40자 이상
- `ideal_candidate`: **'인재유형명: 행동 특성 2-3문장'** 형식, 최소 2개, 각 60자 이상
- `work_environment`: **'제도명: 운영 방식, 도입 배경, 혜택 3-5문장'** 형식, 최소 2개, 각 80자 이상

**swot_analysis 필드별 규격**:

- `strength/weakness/opportunity/threat`: **'제목(헤드라인): 수치 근거 + 인과관계 + 경쟁사 비교 2-4문장'**, 각 카테고리 최소 2개, 각 80자 이상
- `so_strategy / wt_strategy`: SWOT 항목을 **교차 분석**한 전략 2-3문장

---

### 5.3 Phase 3: 면접 파생 (interview_preparation)

**담당 페르소나**: 실무 면접관  
**출력 섹션**: `interview_preparation`

#### 체이닝 메커니즘

Phase 1 + Phase 2의 검증 결과를 모두 주입합니다:

```
## 이전 분석 단계 검증 결과
{Phase 1 company_overview JSON}

{Phase 2 corporate_culture + swot_analysis JSON}
```

#### Phase 3 시스템 프롬프트 핵심 규칙

**핵심 원칙: SWOT 약점/위협 → 압박 면접 질문 1:1 매핑**:

1. 이전 단계 `swot_analysis`에서 `weakness` + `threat` 항목을 **모두 추출**
2. 각 weakness/threat 항목마다 **반드시 1개의 압박 질문** 생성
3. 각 압박 질문의 **첫 문장은 해당 weakness/threat의 구체적 수치/사실을 직접 인용**
4. `expected_answers` 배열 길이 = `pressure_questions` 배열 길이 **(1:1 대응 필수)**

**필드별 규격**:

- `recent_issues`: 최소 3개, 최근 6개월 이내 뉴스, 각 60자 이상
- `pressure_questions`: weakness/threat 수 이상, 각 50자 이상
- `expected_answers`: pressure_questions와 1:1 대응, 각 60자 이상

---

### 5.4 Phase 4: 결과 병합

`_merge_phase_results()` 함수가 3개 Phase의 부분 결과를 최종 1개 `CareerAnalysisReport`로 통합합니다:

```python
# Phase 1에서 company_overview 추출
# Phase 2에서 corporate_culture + swot_analysis 추출
# Phase 3에서 interview_preparation 추출
# → CareerAnalysisReport.model_validate(merged)
```

- 실패한 Phase(None)의 섹션은 **기본값('정보 부족 - 추가 조사 필요')** 으로 채워짐

---

## 6. 검색 시스템 (HybridRM)

### 6.1 아키텍처

```
HybridRM (오케스트레이터)
    |
    |── LLMQueryAnalyzer: 쿼리에서 기업명/분석 의도 추출
    |── CompanyEntityResolver: 약어/별명 → 정규 기업명 + DB ID 매핑
    |       예: "삼전" → (ID: 1, "삼성전자")
    |
    |── PostgresRM (내부 검색)
    |   ├── pgvector 벡터 유사도 검색
    |   ├── 임베딩: Embedding 서비스
    |   └── RerankerService로 재순위
    |
    └── SerperRM (외부 검색)
        ├── Google Serper API 호출
        ├── 국가: kr (한국), 언어: ko
        ├── 시간대 필터: qdr:y (최근 1년)
        └── 블랙리스트 URL 필터링
```

### 6.2 검색 비율 설정

| 파라미터 | 기본값 | 설명 |
|---------|--------|------|
| `internal_k` | 5 | 내부 DB 검색 결과 수 |
| `external_k` | 10 | 외부 Serper 검색 결과 수 |
| `min_score` | 0.5 | 내부 검색 최소 유사도 점수 |

### 6.3 특수 처리

- **영속 이벤트 루프**: `asyncio.new_event_loop()` + `nest_asyncio`로 AsyncOpenAI 크로스-루프 데드락 방지
- **독립 DB 연결**: 각 검색마다 `create_isolated_engine()`으로 독립 세션 생성 (메인 세션과 분리)
- **쿼리 보강**: 엔티티 리졸버가 식별한 기업명을 검색어에 추가

  ```
  "반도체 전망" → "반도체 전망 삼성전자 SK하이닉스"
  ```

---

## 7. 중간 정제 파이프라인 (Intermediate Refinement)

### 7.1 QuestionToQuery (쿼리 확장)

**목적**: 각 검색 질문을 3~5개의 다각화된 검색 쿼리로 확장하여 데이터 커버리지 향상

**사용 모델**: gpt-4o-mini (경량 모델, 비용 최적화)

**시스템 프롬프트 핵심**:

```
1. 하나의 질문에 대해 3~5개의 다각화된 검색 쿼리를 생성
2. 재무 데이터 관련 → '사업보고서', 'DART', '실적' 등 키워드 포함
3. 최신 뉴스 관련 → '{year} 최신', '최근', '뉴스' 등 시간 키워드 포함
4. 각 쿼리에 반드시 기업명 포함
```

**출력 형식**:

```json
{"queries": ["쿼리1", "쿼리2", "쿼리3"]}
```

### 7.2 AnswerQuestion (답변 추출/압축)

**목적**: 검색 결과 원시 스니펫에서 질문에 대한 핵심 답변을 1차 추출/압축

**사용 모델**: gpt-4o-mini

**핵심 규칙**:

- 검색 결과에 **명시적으로 포함된 사실만** 추출 (추측/창작 금지)
- 숫자 데이터는 **단위와 기준 시점** 필수 명시
- 출처 URL을 `[출처: URL]` 형태로 표기
- **300자 이내** 간결한 개조식 압축
- 스니펫 입력은 **3,000자로 제한** (토큰 방어)

**출력 형식**:

```json
{"answer": "추출된 핵심 답변 텍스트"}
```

### 7.3 Map-Reduce 패턴

```
질문 15개 (5개 원본 x 3 확장)
    |
    v
[asyncio.gather] 15개 병렬 AnswerQuestion 호출
    |               (Semaphore: 최대 동시 5개)
    v
{query → refined_answer} 매핑 딕셔너리
    |
    v
_build_refined_llm_context() → 최종 LLM 컨텍스트 문자열 조합
```

---

## 8. SWOT 마이크로 에이전트 시스템

### 8.1 설계 배경

Phase 2에서 단일 LLM 호출로 `corporate_culture` + `swot_analysis`를 동시에 생성하면:

- 출력 토큰 한계로 SWOT 각 항목의 분석 깊이가 얕아짐
- 하나의 카테고리 실패 시 전체 섹션 재생성 필요

**해결**: 5개 독립 마이크로 에이전트로 분할 → 병렬 실행 → 코드 레벨 무손실 병합

### 8.2 에이전트 구성

| # | 에이전트 | 출력 | 모델 | max_tokens |
|---|---------|------|------|-----------|
| 1 | Culture Agent | `corporate_culture` JSON | GPT-4o | 4,000 |
| 2 | Strength Agent | `{"items": ["강점1", ...]}` | GPT-4o | 3,000 |
| 3 | Weakness Agent | `{"items": ["약점1", ...]}` | GPT-4o | 3,000 |
| 4 | Opportunity Agent | `{"items": ["기회1", ...]}` | GPT-4o | 3,000 |
| 5 | Threat Agent | `{"items": ["위협1", ...]}` | GPT-4o | 3,000 |
| 6 | SO/WT Strategy Agent | `{"so_strategy": "...", "wt_strategy": "..."}` | GPT-4o-mini (경량) | 1,000 |

### 8.3 각 SWOT 에이전트 프롬프트 핵심 지침

**공통 품질 규칙 (모든 마이크로 에이전트 상속)**:

1. 단순 칭찬/마케팅 요약 배제, **구체적 수치(%, 금액), 경쟁사 비교, 출처** 포함
2. 각 항목 **300자 이상**의 밀도 높은 분석
3. 재무/실적 수치는 **DART/KIND 확정 실적만** 사용
4. 미래 예측 데이터를 확정 사실처럼 서술 **금지**
5. 모든 수치에 **출처 시점(YYYY년 기준)** 필수 명시

**네거티브 프롬프트 (최우선순위)**:
> 원천 데이터에 구체적 수치가 없다면, 300자 분량 강제를 무시하고 '정보 부족 - 추가 조사 필요'로 출력하십시오. 분량을 채우기 위해 수치를 창작하는 것은 절대 금지입니다.

#### Strength Agent 분석 지침

```
- 시장 점유율, 매출 성장률 등 구체적 수치로 우위를 증명
- 반드시 경쟁사와의 비교 포함 (예: 'A사 대비 점유율 N%p 우위')
- 해당 강점이 기업 경쟁력에 미치는 인과관계 서술
```

#### Weakness Agent 분석 지침

```
- 점유율 하락폭, 영업이익 감소율 등 수치적 열위를 객관적으로 제시
- 경쟁사 대비 뒤처지는 구체적 영역과 그 격차를 명시
- 해당 약점의 구조적 원인(기술 격차, 투자 부족 등) 분석
```

#### Opportunity Agent 분석 지침

```
- 확정된 투자 계획, 체결된 계약, 발표된 정책 등 실제 팩트에 기반
- 시장 규모/성장률은 공인 기관(IDC, Gartner 등) 확정 데이터만 사용
- 해당 기회가 기업에 미치는 구체적 효과(매출 증대, 점유율 확대 등) 서술
```

#### Threat Agent 분석 지침

```
- 구체적 정책명, 규제명, 경쟁사 행동 등 팩트에 기반
- 해당 위협이 기업 실적에 미치는 정량적 영향을 팩트로 서술
- 위협의 시간적 긴급성(즉각적 vs 중장기) 명시
```

#### SO/WT Strategy Agent

```
- 4개 SWOT 항목을 교차 분석하여 SO 전략(강점-기회)과 WT 전략(약점-위협) 도출
- 각 전략은 SWOT 항목의 구체적 내용을 명시적으로 인용하여 연결
```

### 8.4 실행 흐름

```
[asyncio.gather] 5개 에이전트 병렬 실행
    |
    v
개별 결과 파싱 (JSON → 리스트/객체)
    |   - 실패한 에이전트는 기본값('정보 부족') 사용
    |
    v
코드 레벨 무손실 병합
    |   - SwotAnalysis(strength=[], weakness=[], ...)
    |   - CorporateCulture(core_values=[], ...)
    |
    v
SO/WT Strategy Agent (6번째 경량 LLM 호출)
    |   - 4개 SWOT 항목을 입력으로 받아 교차 전략 도출
    |
    v
무손실 검증 (verify_lossless_merge)
    |   - 에이전트 산출물 글자 수 vs 최종 병합 결과 글자 수 100% 일치 확인
    |
    v
최종 SwotAnalysis + CorporateCulture 반환
```

### 8.5 SWOT 에이전트 출력 형식

각 SWOT 에이전트(S/W/O/T)의 출력:

```json
{"items": ["제목(헤드라인): 본문 분석...", "제목(헤드라인): 본문 분석..."]}
```

Culture Agent 출력:

```json
{
    "corporate_culture": {
        "core_values": ["가치명: 상세 설명..."],
        "ideal_candidate": ["인재유형: 상세 설명..."],
        "work_environment": ["제도명: 상세 설명..."]
    }
}
```

SO/WT Strategy Agent 출력:

```json
{"so_strategy": "SO 전략 2-3문장", "wt_strategy": "WT 전략 2-3문장"}
```

---

## 9. NLI 팩트체크 검증 루프

### 9.1 전체 구조

```
JSON 초안 (LLM 생성)
    |
    v
[Evaluator] NLI 기반 환각 탐지 (GPT-4o)
    |
    |── 환각 없음 → 통과 (루프 종료)
    |
    |── 환각 발견 (루프 1회차)
    |       |
    |       v
    |   [Refiner] 자동 교정 (GPT-4o)
    |       |
    |       v
    |   교정된 JSON → Evaluator 재검증 (루프 2회차)
    |
    |── 2회 반복 후에도 환각 잔존
    |       |
    |       v
    |   [force_delete_hallucinations] 강제 삭제
    |       - 해당 문장 자체를 JSON에서 제거
    |       - 배열이 비면 '정보 부족' 기본값 삽입
    |
    v
최종 검증된 JSON 반환
```

### 9.2 Evaluator (심사관 에이전트)

**판정 기준 (NLI 3단계)**:

1. **Entailment (수반)**: 원천 데이터에서 해당 문장을 논리적으로 도출 가능 → **통과**
2. **Neutral (중립)**: 원천 데이터와 직접 관련 없으나 일반 상식 수준 → **통과**
3. **Contradiction (모순/무근거)**: 원천 데이터에 반하거나 근거 없는 수치/사실 포함 → **환각 판정**

**환각 판정 세부 규칙**:

- 원천 데이터에 없는 **구체적 수치**(매출액, 점유율 등) → 환각
- 원천 데이터에 없는 **고유명사**(회사명, 인물명, 제품명) → 환각
- **미래 전망치/추정치**를 확정 사실처럼 서술 → 환각
- '정보 부족' 기본값 필드 → 검증 대상 제외
- 일반적 상식 수준의 서술(예: '경쟁이 심화되고 있다') → 환각 아님

**Evaluator 출력 스키마**:

```json
{
    "has_hallucination": true,
    "findings": [
        {
            "section": "swot_analysis.strength",
            "statement": "환각이 의심되는 원문 문장",
            "reason": "원천 데이터에서 근거를 찾을 수 없는 사유",
            "instruction": "rewrite"
        }
    ],
    "summary": "전체 평가 요약"
}
```

### 9.3 Refiner (교정 에이전트)

**교정 규칙**:

- `instruction: "rewrite"` → 원천 데이터 기반으로 팩트 위주 재작성
- `instruction: "delete"` → JSON에서 완전 삭제, 빈 배열이면 기본값 삽입
- **Evaluator가 지적하지 않은 항목은 절대 수정하지 않음**

### 9.4 강제 삭제 (force_delete_hallucinations)

2회 검증 루프 후에도 환각이 남아있을 때:

- 추가 교정 시도 없이 해당 문장을 **최종 JSON에서 직접 제거**
- 무한 루프를 원천 차단하는 안전장치

---

## 10. LLM Resilience 시스템

### 10.1 동시성 제어

```
[LLMResilienceState] (파이프라인 세션 단위)
    |
    |── 일반 모드: asyncio.Semaphore(5) — 최대 5개 동시 LLM 호출
    |
    └── 안전 모드: asyncio.Semaphore(1) — 연속 429 에러 3회 시 자동 전환
```

### 10.2 재시도 전략

| 파라미터 | 값 | 설명 |
|---------|---|------|
| 최대 재시도 | 5회 | `MAX_RETRIES_PER_CALL` |
| 백오프 시작 | 2초 | `BACKOFF_BASE_DELAY_SEC` |
| 백오프 최대 | 30초 | `BACKOFF_MAX_DELAY_SEC` |
| 안전 모드 임계값 | 연속 3회 429 | `SAFE_MODE_THRESHOLD` |

**지수적 백오프**: 2초 → 4초 → 8초 → 16초 → 30초

### 10.3 재시도 가능한 에러

- **429** Rate Limit 에러
- **5xx** 서버 에러 (500, 502, 503, 504)
- **Timeout** 에러
- **Connection** 에러

### 10.4 Graceful Degradation

모든 재시도 실패 시 예외를 발생시키지 않고 **None을 반환**합니다.  
호출자는 None을 받으면 기본값('정보 부족')으로 폴백합니다.

---

## 11. 최종 출력 스키마

### CareerAnalysisReport (Pydantic V2)

```json
{
    "company_overview": {
        "introduction": "5-10문장 기업 요약 (최소 200자)",
        "industry": "업종 분류",
        "employee_count": "N명 / YYYY년 MM월 기준",
        "location": "본사 전체 주소",
        "financials": {
            "revenue": "N조N억원 / YYYY년 기준",
            "operating_profit": "N조N억원 / YYYY년 기준"
        }
    },
    "corporate_culture": {
        "core_values": ["가치명: 상세 설명 (최소 3개, 각 40자+)"],
        "ideal_candidate": ["인재유형: 상세 설명 (최소 2개, 각 60자+)"],
        "work_environment": ["제도명: 상세 설명 (최소 2개, 각 80자+)"]
    },
    "swot_analysis": {
        "strength": ["헤드라인: 수치 근거 + 인과관계 (각 80자+)"],
        "weakness": ["헤드라인: 수치 근거 + 인과관계 (각 80자+)"],
        "opportunity": ["헤드라인: 수치 근거 + 인과관계 (각 80자+)"],
        "threat": ["헤드라인: 수치 근거 + 인과관계 (각 80자+)"],
        "so_strategy": "강점-기회 교차 전략 2-3문장",
        "wt_strategy": "약점-위협 극복 전략 2-3문장"
    },
    "interview_preparation": {
        "recent_issues": ["최근 이슈 2-3문장 (최소 3개, 각 60자+)"],
        "pressure_questions": ["SWOT 약점/위협 기반 압박 질문 (각 50자+)"],
        "expected_answers": ["전략적 답변 가이드 2-3문장 (각 60자+)"]
    }
}
```

### 기본값 정책

모든 필드의 기본값: `"정보 부족 - 추가 조사 필요"`  
검색 결과가 부족하거나 LLM 호출 실패 시, 이 기본값이 자동 적용됩니다.

---

## 12. 프롬프트 설계 전문

### 12.1 최종 합성 시스템 프롬프트 (FINAL_SYNTHESIS_PROMPT)

```
당신은 대학교 취업지원센터의 AI 기업분석 시스템입니다.
아래 제공된 3명의 전문가(산업 애널리스트, 수석 취업 지원관, 실무 면접관)가 수집한
검색 결과를 종합하여, 취업 준비생을 위한 구조화된 기업 분석 보고서를 작성하십시오.

## 출력 규칙 (엄격 준수)
1. 출력은 반드시 순수 JSON 문자열(Raw String)만 반환하십시오.
2. 마크다운 백틱이나 부연 설명 텍스트를 절대 포함하지 마십시오.
3. 모든 배열(array) 필드는 최소 1개 이상의 항목을 포함해야 합니다.
4. 검색 결과가 부족한 항목은 '정보 부족 - 추가 조사 필요'로 표기하십시오.
5. 매출액, 영업이익 등 재무 데이터는 정확한 단위(원, 만원, 억원)와 기준 연월을 명시하십시오.

## JSON 스키마
{Pydantic 모델에서 동적 생성된 스키마}
```

### 12.2 LLM 사용자 프롬프트 구조

```
분석 대상 기업: {company_name}
분석 주제: {topic}
기준일: {today_str}

## 이전 분석 단계 검증 결과    ← Phase 2, 3에서만 포함
{chaining_context}

아래의 수집 데이터를 종합하여 JSON 분석 보고서를 생성하십시오.

# {company_name} 기업 분석을 위한 정제된 데이터

## 페르소나: 산업 애널리스트
### Q: 삼성전자 주요사업 및 시장점유율
A: [정제된 답변]
출처: [URL 목록]

### Q: 삼성전자 2025 연결재무제표 매출액 영업이익
A: [정제된 답변]
...
```

### 12.3 Few-Shot 예시 구조

각 Phase의 시스템 프롬프트에는 **골든 데이터셋 수준의 상세 예시**가 포함되어 있습니다.  
LLM이 각 필드에 기대하는 콘텐츠 길이와 깊이를 학습하도록 실전 수준의 예시를 제공합니다.

**예시 일부 (Phase 1 - company_overview)**:

```json
{
    "company_overview": {
        "introduction": "삼성전자는 1969년 1월 삼성전자공업으로 시작하였습니다. 백색가전 제품 및 AV 기기의 생산으로 시작하여 1974년 한국반도체, 1980년 한국전자통신을 인수하면서 반도체 사업에도 진출하기 시작하였습니다...(상세 서술 계속)",
        "industry": "반도체 및 반도체 장비 와 전기/전자/제어 분야",
        "employee_count": "124,996명 / 2025년 12월 기준",
        "location": "경기도 수원시 영통구 삼성로 129 (매탄동)",
        "financials": {
            "revenue": "333억6,059억원 / 2025년 기준",
            "operating_profit": "43조6,011억원 / 2025년 기준"
        }
    }
}
```

---

## 13. 파일 구조 맵

```
backend/src/company/
    |
    |── router.py                    # API 엔드포인트 (진입점)
    |
    |── services/
    |   └── storm_service.py         # StormService: Job 생성 + 파이프라인 위임
    |                                  JOBS dict (메모리 상태 관리)
    |
    |── engine/                       # --- 핵심 엔진 ---
    |   |── career_pipeline.py        # 메인 파이프라인 오케스트레이터
    |   |                              run_career_pipeline()
    |   |                              _run_single_phase()
    |   |                              _run_verification_loop()
    |   |                              _merge_phase_results()
    |   |                              _build_llm_context()
    |   |                              _build_refined_llm_context()
    |   |                              _build_final_prompt()
    |   |                              _call_llm()
    |   |                              _build_chaining_context()
    |   |
    |   |── personas.py               # 페르소나 정의 + 쿼리 큐 + 시스템 프롬프트
    |   |                              INDUSTRY_ANALYST, CAREER_ADVISOR, PRACTICAL_INTERVIEWER
    |   |                              build_query_queue()
    |   |                              PHASE1/2/3_SYSTEM_PROMPT
    |   |                              마이크로 에이전트 프롬프트 (CULTURE/STRENGTH/WEAKNESS/...)
    |   |
    |   |── swot_agents.py            # SWOT 마이크로 에이전트 분할 + 무손실 병합
    |   |                              run_phase2_micro_agents()
    |   |                              verify_lossless_merge()
    |   |
    |   |── evaluator.py              # NLI 팩트체크 Evaluator (심사관)
    |   |                              evaluate_report()
    |   |                              HallucinationFinding, EvaluationResult
    |   |
    |   |── refiner.py                # 자동 교정 Refiner (교정관)
    |   |                              refine_report()
    |   |                              force_delete_hallucinations()
    |   |
    |   |── intermediate_refinement.py # 중간 정제 (QuestionToQuery + AnswerQuestion)
    |   |                               expand_queries()
    |   |                               extract_answer()
    |   |                               refine_search_results()
    |   |
    |   |── retriever.py              # 검색 엔진
    |   |                              HybridRM (오케스트레이터)
    |   |                              PostgresRM (내부 벡터 검색)
    |   |                              SerperRM (외부 Google 검색)
    |   |
    |   |── builder.py                # HybridRM, LM Config 빌더
    |   |
    |   |── llm_resilience.py         # LLM 동시성 제어 + 백오프 + 안전모드
    |   |                              resilient_llm_call()
    |   |                              LLMResilienceState
    |   |
    |   |── schema_utils.py           # Pydantic → JSON 스키마 동적 생성
    |   |
    |   |── json_utils.py             # JSON 파싱 유틸리티
    |   |
    |   |── ingestion.py              # 검색 결과 비동기 DB 적재
    |   |
    |   |── adapter.py                # DB 저장 어댑터
    |   |
    |   └── io.py                     # 파일 I/O (디렉토리 생성, 메타데이터 기록)
    |
    |── schemas/
    |   └── career_report.py          # 최종 출력 스키마 (Pydantic V2)
    |                                   CareerAnalysisReport
    |                                   CompanyOverview, CorporateCulture
    |                                   SwotAnalysis, InterviewPreparation
    |
    |── models/                        # SQLAlchemy DB 모델
    |
    └── repositories/                  # DB 접근 레이어
```

---

## 부록: 핵심 상수 정리

| 상수명 | 값 | 위치 | 설명 |
|--------|---|------|------|
| `MAX_LLM_RETRIES` | 2 | career_pipeline.py | JSON 파싱 실패 시 LLM 재호출 횟수 |
| `MAX_VERIFICATION_LOOPS` | 2 | career_pipeline.py | NLI 검증 최대 반복 횟수 |
| `MAX_CONTEXT_CHARS` | 50,000 | career_pipeline.py | LLM 입력 컨텍스트 최대 글자 수 |
| `MAX_CHAINING_CHARS` | 30,000 | career_pipeline.py | 체이닝 컨텍스트 최대 글자 수 |
| `MAX_GLOBAL_LLM_CONCURRENCY` | 5 | llm_resilience.py | 최대 동시 LLM 호출 수 |
| `BACKOFF_BASE_DELAY_SEC` | 2.0 | llm_resilience.py | 지수적 백오프 시작 지연 |
| `MAX_RETRIES_PER_CALL` | 5 | llm_resilience.py | 개별 LLM 호출 최대 재시도 |
| `SAFE_MODE_THRESHOLD` | 3 | llm_resilience.py | 안전모드 전환 연속 429 횟수 |
| `MAX_CONCURRENT_LLM_CALLS` | 5 | intermediate_refinement.py | AnswerQuestion 동시성 제한 |
| `internal_k` | 5 | builder.py | 내부 DB 검색 결과 수 |
| `external_k` | 10 | builder.py | 외부 Serper 검색 결과 수 |
