#!/usr/bin/env python
"""
Entity Bias ë°©ì§€ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

FEAT-Retriever-001-EntityBias ì‘ì—… ê²€ì¦ìš© ìŠ¤í¬ë¦½íŠ¸

í…ŒìŠ¤íŠ¸ í•­ëª©:
1. Entity ì¶”ì¶œ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
2. Entity ë§¤ì¹­ ë¦¬ë­í‚¹ í…ŒìŠ¤íŠ¸ (Mock)
3. ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ í…ŒìŠ¤íŠ¸ (DB ì—°ê²° í•„ìš”)

Usage:
    python -m test.test_entity_bias
"""

import os
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def test_entity_extraction():
    """Entity ì¶”ì¶œ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ 1: Entity ì¶”ì¶œ (_extract_target_entities)")
    print("=" * 60)

    from knowledge_storm.db.postgres_connector import PostgresConnector

    # PostgresConnectorì˜ _extract_target_entitiesë§Œ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ
    # DB ì—°ê²° ì—†ì´ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ í•¨ìˆ˜ë¥¼ ë¶„ë¦¬
    from src.common.config import COMPANY_ALIASES, get_all_aliases

    def extract_target_entities(query: str):
        """í…ŒìŠ¤íŠ¸ìš© Entity ì¶”ì¶œ (PostgresConnector._extract_target_entitiesì™€ ë™ì¼ ë¡œì§)"""
        target_keywords = []
        for canonical, aliases in COMPANY_ALIASES.items():
            all_names = [canonical] + aliases
            for name in all_names:
                if name.lower() in query.lower():
                    target_keywords = get_all_aliases(canonical)
                    return target_keywords
        return target_keywords

    test_cases = [
        ("SKí•˜ì´ë‹‰ìŠ¤ ë§¤ì¶œ í˜„í™©", ["SKí•˜ì´ë‹‰ìŠ¤", "í•˜ì´ë‹‰ìŠ¤", "SK Hynix", "Hynix", "ì—ìŠ¤ì¼€ì´í•˜ì´ë‹‰ìŠ¤", "SKí•˜ì´ë‹‰ìŠ¤ãˆœ"]),
        ("ì‚¼ì„±ì „ì ê¸°ì—… ê°œìš”", ["ì‚¼ì„±ì „ì", "ì‚¼ì „", "Samsung Electronics", "Samsung", "ì‚¼ì„±ì „ìãˆœ", "SAMSUNG"]),
        ("SK Hynix revenue analysis", ["SKí•˜ì´ë‹‰ìŠ¤", "í•˜ì´ë‹‰ìŠ¤", "SK Hynix", "Hynix", "ì—ìŠ¤ì¼€ì´í•˜ì´ë‹‰ìŠ¤", "SKí•˜ì´ë‹‰ìŠ¤ãˆœ"]),
        ("ë°˜ë„ì²´ ì‹œì¥ ë™í–¥", []),  # ê¸°ì—…ëª… ì—†ìŒ
    ]

    all_passed = True
    for query, expected in test_cases:
        result = extract_target_entities(query)
        # ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œ(ì •ê·œëª…)ê°€ ê°™ì€ì§€ í™•ì¸
        if expected:
            match = len(result) > 0 and result[0] == expected[0]
        else:
            match = len(result) == 0
        status = "âœ…" if match else "âŒ"
        print(f"  {status} Query: '{query}'")
        print(f"       ê²°ê³¼: {result[:3]}... (ì˜ˆìƒ: {expected[:3]}...)" if result else f"       ê²°ê³¼: {result}")
        if not match:
            all_passed = False

    print(f"\nğŸ í…ŒìŠ¤íŠ¸ 1 ê²°ê³¼: {'âœ… PASS' if all_passed else 'âŒ FAIL'}")
    return all_passed


def test_entity_reranking_mock():
    """Entity ë§¤ì¹­ ë¦¬ë­í‚¹ í…ŒìŠ¤íŠ¸ (Mock ë°ì´í„°)"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ 2: Entity ë§¤ì¹­ ë¦¬ë­í‚¹ (Mock)")
    print("=" * 60)

    # Mock ê²€ìƒ‰ ê²°ê³¼
    mock_results = [
        {
            "content": "SKí•˜ì´ë‹‰ìŠ¤ëŠ” DRAM ë° NAND Flash ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ì „ë¬¸ ê¸°ì—…ì…ë‹ˆë‹¤.",
            "title": "1. íšŒì‚¬ì˜ ê°œìš”",
            "url": "dart_report_2_chunk_100",
            "score": 0.85,
        },
        {
            "content": "[í‘œ ë°ì´í„°]\n| í•­ëª© | ì‚¼ì„±ì „ì | SKí•˜ì´ë‹‰ìŠ¤ |\n|---|---|---|\n| ë§¤ì¶œ | 100ì¡° | 50ì¡° |",
            "title": "ê²½ìŸì‚¬ ë¹„êµ",
            "url": "dart_report_1_chunk_66",
            "score": 0.88,  # ì›ë˜ ë” ë†’ì€ ì ìˆ˜
        },
        {
            "content": "[í‘œ ë°ì´í„°]\nì‚¼ì„±ì „ì ì´ì‚¬íšŒ ëª…ë‹¨...",
            "title": "ì´ì‚¬íšŒ êµ¬ì„±",
            "url": "dart_report_1_chunk_200",
            "score": 0.75,
        },
    ]

    # ë¦¬ë­í‚¹ ë¡œì§ (PostgresConnector._rerank_by_entity_matchì™€ ë™ì¼)
    from src.common.config import COMPANY_ALIASES, get_all_aliases

    query = "SKí•˜ì´ë‹‰ìŠ¤ ë§¤ì¶œ í˜„í™©"
    boost_multiplier = 1.3
    penalty_multiplier = 0.5
    drop_unmatched_tables = True

    # Entity ì¶”ì¶œ
    target_keywords = []
    for canonical, aliases in COMPANY_ALIASES.items():
        all_names = [canonical] + aliases
        for name in all_names:
            if name.lower() in query.lower():
                target_keywords = get_all_aliases(canonical)
                break
        if target_keywords:
            break

    print(f"  Query: '{query}'")
    print(f"  Target keywords: {target_keywords[:3]}...")
    print()

    reranked_results = []
    dropped_count = 0

    for doc in mock_results:
        doc_title = doc.get('title', '')
        doc_content = doc.get('content', '')[:500]
        doc_meta = f"{doc_title} {doc_content}".lower()

        is_matched = any(keyword.lower() in doc_meta for keyword in target_keywords)
        is_table_chunk = "[í‘œ ë°ì´í„°]" in doc.get('content', '')
        original_score = doc.get('score', 0)

        if is_matched:
            doc['score'] = original_score * boost_multiplier
            doc['_entity_match'] = True
            print(f"  âœ… MATCH: {doc['url']} | Score: {original_score:.4f} â†’ {doc['score']:.4f}")
            reranked_results.append(doc)
        else:
            if is_table_chunk and drop_unmatched_tables:
                dropped_count += 1
                print(f"  ğŸ—‘ï¸ DROP: {doc['url']} (Table + Entity ë¶ˆì¼ì¹˜)")
                continue
            doc['score'] = original_score * penalty_multiplier
            doc['_entity_match'] = False
            print(f"  âš ï¸ PENALTY: {doc['url']} | Score: {original_score:.4f} â†’ {doc['score']:.4f}")
            reranked_results.append(doc)

    reranked_results.sort(key=lambda x: x.get('score', 0), reverse=True)

    print()
    print(f"  ğŸ“Š ê²°ê³¼: {len(reranked_results)}ê°œ ìœ ì§€, {dropped_count}ê°œ ë“œë¡­")
    print(f"  ğŸ“Š ìµœì¢… ìˆœìœ„:")
    for i, r in enumerate(reranked_results, 1):
        print(f"       {i}. {r['url']} (score: {r['score']:.4f}, match: {r.get('_entity_match', 'N/A')})")

    # ê²€ì¦:
    # - ì‚¼ì„± ë‹¨ë… í…Œì´ë¸”(chunk_200)ì€ ë“œë¡­ë˜ì–´ì•¼ í•¨
    # - ê²½ìŸì‚¬ ë¹„êµ í‘œ(chunk_66)ëŠ” SKí•˜ì´ë‹‰ìŠ¤ í¬í•¨ì´ë¯€ë¡œ ë§¤ì¹­ë˜ì–´ ì‚´ì•„ë‚¨ìŒ
    # - SKí•˜ì´ë‹‰ìŠ¤ ê°œìš”(chunk_100)ë„ ë§¤ì¹­ë˜ì–´ ì‚´ì•„ë‚¨ìŒ
    # - ëª¨ë‘ ë§¤ì¹­ë˜ë¯€ë¡œ ì›ë˜ ì ìˆ˜ ìˆœì„œëŠ” ìœ ì§€ë˜ë˜, ë¶€ìŠ¤íŠ¸ê°€ ì ìš©ë¨

    print(f"\n  ğŸ” ê²€ì¦:")
    print(f"       len(reranked_results) == 2: {len(reranked_results) == 2} (actual: {len(reranked_results)})")
    print(f"       dropped_count == 1: {dropped_count == 1} (actual: {dropped_count})")
    print(f"       all matched: {all(r.get('_entity_match') for r in reranked_results)}")
    print(f"       matches: {[r.get('_entity_match') for r in reranked_results]}")

    success = (
        len(reranked_results) == 2 and  # ì‚¼ì„± ë‹¨ë… í…Œì´ë¸”(chunk_200) ë“œë¡­ë¨
        dropped_count == 1 and
        all(r.get('_entity_match') for r in reranked_results)  # ëª¨ë‘ ë§¤ì¹­ë¨
    )

    print(f"\nğŸ í…ŒìŠ¤íŠ¸ 2 ê²°ê³¼: {'âœ… PASS' if success else 'âŒ FAIL'}")
    return success


def test_real_search():
    """ì‹¤ì œ DB ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ 3: ì‹¤ì œ DB ê²€ìƒ‰ (Entity Bias ë°©ì§€ ê²€ì¦)")
    print("=" * 60)

    try:
        from knowledge_storm.db.postgres_connector import PostgresConnector

        connector = PostgresConnector()
        print("  âœ… PostgresConnector ì´ˆê¸°í™” ì„±ê³µ")

        # í…ŒìŠ¤íŠ¸ 1: SKí•˜ì´ë‹‰ìŠ¤ ì¿¼ë¦¬
        query = "SKí•˜ì´ë‹‰ìŠ¤ ë§¤ì¶œ í˜„í™©"
        print(f"\n  Query: '{query}'")
        results = connector.search(query, top_k=5)

        print(f"  Found: {len(results)} results")

        # ì‚¼ì„±ì „ì ê´€ë ¨ ì²­í¬ê°€ ìƒìœ„ì— ìˆëŠ”ì§€ í™•ì¸
        samsung_in_top = False
        for i, r in enumerate(results, 1):
            is_samsung = "ì‚¼ì„±" in r['content'] and "í•˜ì´ë‹‰ìŠ¤" not in r['content']
            entity_match = r.get('_entity_match', 'N/A')
            print(f"       {i}. score={r['score']:.4f}, match={entity_match}, title={r['title'][:30]}...")
            if is_samsung and i <= 3:  # ìƒìœ„ 3ê°œ ë‚´ì— ì‚¼ì„± ë‹¨ë… ì²­í¬ê°€ ìˆìœ¼ë©´ ë¬¸ì œ
                samsung_in_top = True

        # í…ŒìŠ¤íŠ¸ 2: ì‚¼ì„±ì „ì ì¿¼ë¦¬
        query2 = "ì‚¼ì„±ì „ì ê¸°ì—… ê°œìš”"
        print(f"\n  Query: '{query2}'")
        results2 = connector.search(query2, top_k=5)

        print(f"  Found: {len(results2)} results")
        for i, r in enumerate(results2, 1):
            entity_match = r.get('_entity_match', 'N/A')
            print(f"       {i}. score={r['score']:.4f}, match={entity_match}, title={r['title'][:30]}...")

        connector.close()

        # ê²€ì¦
        success = not samsung_in_top
        print(f"\nğŸ í…ŒìŠ¤íŠ¸ 3 ê²°ê³¼: {'âœ… PASS' if success else 'âŒ FAIL (ì‚¼ì„± ì²­í¬ê°€ ìƒìœ„ì— ë…¸ì¶œ)'}")
        return success

    except Exception as e:
        print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("     (DB ì—°ê²°ì´ í•„ìš”í•œ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤)")
        return None  # ìŠ¤í‚µ


def main():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸš€ Entity Bias ë°©ì§€ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    results = []

    # í…ŒìŠ¤íŠ¸ 1: Entity ì¶”ì¶œ
    results.append(("Entity ì¶”ì¶œ", test_entity_extraction()))

    # í…ŒìŠ¤íŠ¸ 2: Mock ë¦¬ë­í‚¹
    results.append(("Mock ë¦¬ë­í‚¹", test_entity_reranking_mock()))

    # í…ŒìŠ¤íŠ¸ 3: ì‹¤ì œ DB ê²€ìƒ‰
    results.append(("ì‹¤ì œ DB ê²€ìƒ‰", test_real_search()))

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)

    for name, passed in results:
        if passed is None:
            status = "â­ï¸ SKIP"
        elif passed:
            status = "âœ… PASS"
        else:
            status = "âŒ FAIL"
        print(f"  {status}: {name}")

    all_passed = all(p for p in [r[1] for r in results] if p is not None)
    print()
    print(f"ğŸ ìµœì¢… ê²°ê³¼: {'âœ… ALL PASSED' if all_passed else 'âŒ SOME FAILED'}")


if __name__ == "__main__":
    main()

