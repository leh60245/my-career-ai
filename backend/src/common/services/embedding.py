import asyncio
import inspect
import logging
import os
from abc import ABC, abstractmethod
from typing import Optional

from openai import AsyncOpenAI


try:
    from ..config import EMBEDDING_CONFIG
except ImportError:
    EMBEDDING_CONFIG = {
        "provider": "openai",
        "openai_model": "text-embedding-3-small",
        "hf_model": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
        "dimension": 1536,
        "batch_size": 32,
        "max_length": 512,
    }

logger = logging.getLogger(__name__)


def get_optimal_device() -> str:
    """Return the best available accelerator."""
    try:
        import torch

        if torch.cuda.is_available():
            return "cuda"
        if torch.backends.mps.is_available():
            return "mps"
    except ImportError:
        pass
    return "cpu"


class BaseEmbedder(ABC):
    """ìž„ë² ë”© ìƒì„±ê¸° ì¶”ìƒ ê¸°ë³¸ í´ëž˜ìŠ¤"""

    @abstractmethod
    async def get_embeddings(self, texts: list[str]) -> list[list[float]]:
        """
        [Async] í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•œ ìž„ë² ë”© ë²¡í„° ë°˜í™˜
        """
        pass

    @abstractmethod
    def get_dimension(self) -> int:
        """ìž„ë² ë”© ì°¨ì› ìˆ˜ ë°˜í™˜"""
        pass

    async def aclose(self) -> None:
        """Optional async close hook for underlying clients."""
        return


class OpenAIEmbedder(BaseEmbedder):
    """
    OpenAI API ê¸°ë°˜ ë¹„ë™ê¸° ìž„ë² ë”© ìƒì„±ê¸° (AsyncOpenAI)
    """

    def __init__(self, model_name: str | None = None, api_key: str | None = None):
        self.model_name = model_name or EMBEDDING_CONFIG.get("openai_model", "text-embedding-3-small")
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")

        # 1536 for text-embedding-3-small, 3072 for large
        self._dimension = 1536 if "small" in self.model_name else 3072
        if "dimension" in EMBEDDING_CONFIG:
            self._dimension = EMBEDDING_CONFIG["dimension"]

        if not self.api_key:
            logger.warning("âš ï¸ OPENAI_API_KEY is missing. Embeddings will fail.")
            self.client = None
        else:
            self.client = AsyncOpenAI(api_key=self.api_key)
            logger.info(f"âœ… OpenAI Async Embedder initialized: {self.model_name}")

    def get_dimension(self) -> int:
        return self._dimension

    async def get_embeddings(self, texts: list[str]) -> list[list[float]]:
        if not texts or not self.client:
            return []

        try:
            # ê³µë°±/Newlines ì •ë¦¬ (ìž„ë² ë”© í’ˆì§ˆ í–¥ìƒ)
            sanitized_texts = [text.replace("\n", " ") for text in texts]

            # Async API í˜¸ì¶œ
            response = await self.client.embeddings.create(input=sanitized_texts, model=self.model_name)

            # OpenAIëŠ” ìž…ë ¥ ìˆœì„œë¥¼ ë³´ìž¥í•¨
            return [data.embedding for data in response.data]

        except Exception as e:
            logger.error(f"Failed to generate embeddings (OpenAI): {e}")
            return []

    async def aclose(self) -> None:
        if not self.client:
            return
        close_fn = getattr(self.client, "aclose", None) or getattr(self.client, "close", None)
        if not close_fn:
            return
        result = close_fn()
        if inspect.isawaitable(result):
            await result


class HuggingFaceEmbedder(BaseEmbedder):
    """
    HuggingFace ë¡œì»¬ ëª¨ë¸ ê¸°ë°˜ ìž„ë² ë”© ìƒì„±ê¸°
    CPU/GPU ì—°ì‚°ì´ ë¬´ê±°ìš°ë¯€ë¡œ ThreadPoolExecutorì—ì„œ ì‹¤í–‰í•˜ì—¬ ì´ë²¤íŠ¸ ë£¨í”„ ì°¨ë‹¨ ë°©ì§€
    """

    def __init__(self, model_name: str | None = None, device: str | None = None, batch_size: int | None = None):
        self.model_name = model_name or EMBEDDING_CONFIG.get("hf_model", "sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
        self.batch_size = batch_size or EMBEDDING_CONFIG.get("batch_size", 32)
        self.device = device or get_optimal_device()

        logger.info(f"ðŸ”„ Loading HuggingFace model: {self.model_name} on {self.device.upper()}")

        # Lazy Import
        from transformers import AutoModel, AutoTokenizer

        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModel.from_pretrained(self.model_name)
        self.model.to(self.device)
        self.model.eval()

        self._dimension = self.model.config.hidden_size
        logger.info(f"âœ… HuggingFace Model loaded (dim: {self._dimension})")

    def get_dimension(self) -> int:
        return self._dimension

    def _embed_sync(self, texts: list[str]) -> list[list[float]]:
        """[Sync] ì‹¤ì œ ì—°ì‚° ìˆ˜í–‰ (Blocking)"""
        import torch

        all_embeddings = []
        # Batch Processing
        for i in range(0, len(texts), self.batch_size):
            batch = texts[i : i + self.batch_size]

            encoded_input = self.tokenizer(batch, padding=True, truncation=True, max_length=512, return_tensors="pt")
            encoded_input = {k: v.to(self.device) for k, v in encoded_input.items()}

            with torch.no_grad():
                model_output = self.model(**encoded_input)

            # Mean Pooling
            token_embeddings = model_output[0]
            attention_mask = encoded_input["attention_mask"]

            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
            sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)
            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)
            embeddings = sum_embeddings / sum_mask

            # Normalize
            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
            all_embeddings.extend(embeddings.cpu().tolist())

        return all_embeddings

    async def get_embeddings(self, texts: list[str]) -> list[list[float]]:
        """[Async Wrapper] ThreadPoolì—ì„œ ë™ê¸° ë©”ì„œë“œ ì‹¤í–‰"""
        if not texts:
            return []

        loop = asyncio.get_running_loop()
        try:
            # CPU Blocking ë°©ì§€ë¥¼ ìœ„í•´ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            return await loop.run_in_executor(None, self._embed_sync, texts)
        except Exception as e:
            logger.error(f"Failed to generate embeddings (HF): {e}")
            return []


class Embedding:
    """
    í†µí•© ìž„ë² ë”© ì„œë¹„ìŠ¤ (Singleton & Strategy Pattern)
    IngestionService ë° ê²€ìƒ‰ ì„œë¹„ìŠ¤ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©
    """

    _instance: Optional["Embedding"] = None
    _embedder: BaseEmbedder | None = None

    def __new__(cls, provider: str | None = None, **kwargs):
        target_provider = provider or EMBEDDING_CONFIG.get("provider", "openai")

        # ì¸ìŠ¤í„´ìŠ¤ê°€ ì—†ê±°ë‚˜ í”„ë¡œë°”ì´ë”ê°€ ë°”ë€Œë©´ ìž¬ìƒì„±
        if cls._instance is None or cls._instance._provider != target_provider:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False

        return cls._instance

    def __init__(self, provider: str | None = None, **kwargs):
        if getattr(self, "_initialized", False):
            return

        self._provider = provider or EMBEDDING_CONFIG.get("provider", "openai")
        logger.info(f"ðŸš€ Initializing EmbeddingService with provider: {self._provider}")

        if self._provider == "openai":
            self._embedder = OpenAIEmbedder(**kwargs)
        elif self._provider == "huggingface":
            self._embedder = HuggingFaceEmbedder(**kwargs)
        else:
            raise ValueError(f"Unsupported provider: {self._provider}")

        self._initialized = True

    async def get_embeddings(self, texts: list[str]) -> list[list[float]]:
        """
        [Standard Async Interface]
        í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ìž…ë ¥ë°›ì•„ ìž„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if not self._embedder:
            logger.error("Embedder not initialized.")
            return []

        return await self._embedder.get_embeddings(texts)

    async def aclose(self) -> None:
        if self._embedder and hasattr(self._embedder, "aclose"):
            await self._embedder.aclose()

    @property
    def dimension(self) -> int:
        if not self._embedder:
            raise RuntimeError("Embedder not initialized.")
        return self._embedder.get_dimension()

    @classmethod
    def get_instance(cls) -> Optional["Embedding"]:
        return cls._instance
