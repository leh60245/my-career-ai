"""
í†µí•© ì„¤ì • ëª¨ë“ˆ (Unified Configuration)

AIì™€ Ingestion ì–‘ìª½ì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ì„¤ì •ì„ ì¤‘ì•™ ê´€ë¦¬í•©ë‹ˆë‹¤.
í™˜ê²½ë³€ìˆ˜ ë„¤ì´ë°ì„ í†µì¼í•˜ê³  ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤.

í™˜ê²½ë³€ìˆ˜ í‘œì¤€:
- DB: PG_HOST, PG_PORT, PG_USER, PG_PASSWORD, PG_DATABASE
- AI: OPENAI_API_KEY, GOOGLE_API_KEY, ENCODER_API_TYPE
- DART: DART_API_KEY
"""
import os
from pathlib import Path
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ .env ë¡œë“œ
_project_root = Path(__file__).parent.parent.parent
_env_path = _project_root / ".env"
if _env_path.exists():
    load_dotenv(_env_path)
else:
    load_dotenv()  # ê¸°ë³¸ .env ë¡œë“œ ì‹œë„


# =============================================================================
# Database Configuration (í†µí•©)
# =============================================================================
# í™˜ê²½ë³€ìˆ˜ í˜¸í™˜ì„±: PG_* (ì‹ ê·œ í‘œì¤€) ìš°ì„ , DB_* (ë ˆê±°ì‹œ) í´ë°±
DB_CONFIG = {
    "host": os.getenv("PG_HOST") or os.getenv("DB_HOST", "localhost"),
    "port": os.getenv("PG_PORT") or os.getenv("DB_PORT", "5432"),
    "user": os.getenv("PG_USER") or os.getenv("DB_USER", "postgres"),
    "password": os.getenv("PG_PASSWORD") or os.getenv("DB_PASSWORD"),
    "database": os.getenv("PG_DATABASE") or os.getenv("DB_NAME", "postgres"),
}


# =============================================================================
# Embedding Configuration (í†µí•© - ê°€ì¥ ì¤‘ìš”!)
# =============================================================================
# âš ï¸ ê²½ê³ : DB Vector Indexì™€ ë™ì¼í•œ ëª¨ë¸/ì°¨ì›ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤!
# HuggingFace(768D) â†” OpenAI(1536D) ë¶ˆì¼ì¹˜ ì‹œ ì‹œìŠ¤í…œ ì¦‰ì‹œ ì¤‘ë‹¨ë©ë‹ˆë‹¤.
#
# í”„ë¡œë°”ì´ë” ë³€ê²½ ì‹œ í•„ìˆ˜ ì‘ì—…:
# 1. ê¸°ì¡´ DBì˜ ëª¨ë“  ì„ë² ë”© ì‚­ì œ (UPDATE "Source_Materials" SET embedding = NULL)
# 2. pgvector ì¸ë±ìŠ¤ ì¬ìƒì„±
# 3. ì „ì²´ ë°ì´í„° ì¬ì„ë² ë”© (python -m scripts.run_ingestion --embed --force)

# ============== í™œì„± ëª¨ë¸ ì„¤ì • (ëŸ°íƒ€ì„ ì¤‘ í•˜ë‚˜ë§Œ í™œì„±í™”) ==============
ACTIVE_EMBEDDING_PROVIDER = os.getenv("EMBEDDING_PROVIDER", "huggingface")

# í—ˆìš©ëœ í”„ë¡œë°”ì´ë” ëª©ë¡
_ALLOWED_PROVIDERS = ["huggingface", "openai"]

if ACTIVE_EMBEDDING_PROVIDER not in _ALLOWED_PROVIDERS:
    raise RuntimeError(
        f"Invalid EMBEDDING_PROVIDER: {ACTIVE_EMBEDDING_PROVIDER}. "
        f"Allowed values: {', '.join(_ALLOWED_PROVIDERS)}"
    )

# ============== í”„ë¡œë°”ì´ë”ë³„ ì„¤ì • ==============
EMBEDDING_CONFIG = {
    # í™œì„± í”„ë¡œë°”ì´ë” (ëŸ°íƒ€ì„ ì¤‘ ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€!)
    "provider": ACTIVE_EMBEDDING_PROVIDER,

    # HuggingFace ì„¤ì • (768ì°¨ì› - ë‹¤êµ­ì–´ ì§€ì›)
    "hf_model": os.getenv(
        "HF_EMBEDDING_MODEL",
        "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
    ),
    "hf_dimension": 768,

    # OpenAI ì„¤ì • (1536ì°¨ì› - ë†’ì€ ì •í™•ë„, ë¹„ìš© ë°œìƒ)
    "openai_model": os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small"),
    "openai_dimension": 1536,

    # ê³µí†µ ì„¤ì •
    "batch_size": int(os.getenv("EMBEDDING_BATCH_SIZE", "32")),
    "max_length": int(os.getenv("EMBEDDING_MAX_LENGTH", "512")),
}

# ============== í™œì„± ì°¨ì› ìë™ ê²°ì • ==============
if ACTIVE_EMBEDDING_PROVIDER == "openai":
    EMBEDDING_CONFIG["dimension"] = EMBEDDING_CONFIG["openai_dimension"]
    EMBEDDING_CONFIG["model_name"] = EMBEDDING_CONFIG["openai_model"]
else:  # huggingface
    EMBEDDING_CONFIG["dimension"] = EMBEDDING_CONFIG["hf_dimension"]
    EMBEDDING_CONFIG["model_name"] = EMBEDDING_CONFIG["hf_model"]

# ============== ëŸ°íƒ€ì„ ê²€ì¦ (ì°¨ì› ë¶ˆì¼ì¹˜ ì¡°ê¸° ê°ì§€) ==============
def validate_embedding_dimension_compatibility():
    """
    DBì— ì €ì¥ëœ ë²¡í„° ì°¨ì›ê³¼ í˜„ì¬ ì„¤ì • ì°¨ì›ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.

    ë¶ˆì¼ì¹˜ ì‹œ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ì™€ í•¨ê»˜ ì¦‰ì‹œ ì¤‘ë‹¨í•©ë‹ˆë‹¤.

    Returns:
        bool: ê²€ì¦ ì„±ê³µ ì‹œ True

    Raises:
        RuntimeError: ì°¨ì› ë¶ˆì¼ì¹˜ ë˜ëŠ” DB ì—°ê²° ì‹¤íŒ¨ ì‹œ
    """
    try:
        from .db_connection import get_db_connection

        with get_db_connection() as conn:
            cursor = conn.cursor()

            # Source_Materials í…Œì´ë¸”ì˜ embedding ì»¬ëŸ¼ ì°¨ì› í™•ì¸
            cursor.execute("""
                SELECT 
                    atttypmod 
                FROM pg_attribute 
                WHERE attrelid = '"Source_Materials"'::regclass 
                  AND attname = 'embedding'
            """)

            result = cursor.fetchone()
            if not result:
                # í…Œì´ë¸”ì´ ì—†ê±°ë‚˜ embedding ì»¬ëŸ¼ì´ ì—†ìŒ (ì´ˆê¸° ìƒíƒœ)
                return True

            # atttypmodì—ì„œ ì°¨ì› ì¶”ì¶œ (pgvectorëŠ” ì°¨ì›+4ë¡œ ì €ì¥)
            db_dimension = result[0] - 4 if result[0] > 0 else None

            if db_dimension is None:
                return True  # ì°¨ì› ì •ë³´ ì—†ìŒ (ì´ˆê¸° ìƒíƒœ)

            current_dimension = EMBEDDING_CONFIG["dimension"]

            if db_dimension != current_dimension:
                raise RuntimeError(
                    f"\n{'='*70}\n"
                    f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜ (Dimension Mismatch)\n"
                    f"{'='*70}\n"
                    f"DBì— ì €ì¥ëœ ë²¡í„° ì°¨ì›: {db_dimension}D\n"
                    f"í˜„ì¬ ì„¤ì •ëœ ì°¨ì›:     {current_dimension}D (provider={ACTIVE_EMBEDDING_PROVIDER})\n"
                    f"\n"
                    f"ì›ì¸:\n"
                    f"  - DBëŠ” ë‹¤ë¥¸ ì„ë² ë”© ëª¨ë¸ë¡œ ìƒì„±ëœ ë²¡í„°ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
                    f"  - ì°¨ì›ì´ ë‹¤ë¥¸ ë²¡í„°ë¡œ ê²€ìƒ‰ ì‹œ PostgreSQL ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n"
                    f"\n"
                    f"í•´ê²° ë°©ë²•:\n"
                    f"  1. [ì˜µì…˜ A] ê¸°ì¡´ DB ì°¨ì›ì— ë§ê²Œ ì„¤ì • ë³€ê²½:\n"
                    f"     .env íŒŒì¼ì—ì„œ EMBEDDING_PROVIDERë¥¼ "
                    f"{'openai' if db_dimension == 1536 else 'huggingface'}ë¡œ ë³€ê²½\n"
                    f"\n"
                    f"  2. [ì˜µì…˜ B] ìƒˆ ëª¨ë¸ë¡œ ì „ì²´ ì¬ì„ë² ë”© (ì‹œê°„ ì†Œìš”):\n"
                    f"     â‘  DB ë°±ì—…: pg_dump corp_analysis > backup.sql\n"
                    f"     â‘¡ ì„ë² ë”© ì´ˆê¸°í™”: UPDATE \"Source_Materials\" SET embedding = NULL\n"
                    f"     â‘¢ ì¬ì„ë² ë”©: python -m scripts.run_ingestion --embed --force\n"
                    f"\n"
                    f"  3. [ì˜µì…˜ C] DB ì™„ì „ ì´ˆê¸°í™” í›„ ì¬ìˆ˜ì§‘:\n"
                    f"     python -m scripts.run_ingestion --test --reset-db\n"
                    f"{'='*70}\n"
                )

            return True

    except ImportError:
        # db_connection ëª¨ë“ˆì´ ì—†ëŠ” ê²½ìš° (ì˜ˆ: ì„¤ì • ë¡œë“œ ë‹¨ê³„)
        return True
    except Exception as e:
        # DB ì—°ê²° ì‹¤íŒ¨ ë“±ì€ ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ì§„í–‰
        import warnings
        warnings.warn(
            f"ì„ë² ë”© ì°¨ì› ê²€ì¦ ì‹¤íŒ¨ (DB ì—°ê²° ë¶ˆê°€): {e}\n"
            f"ë‚˜ì¤‘ì— DB ì ‘ê·¼ ì‹œ ì°¨ì› ë¶ˆì¼ì¹˜ ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            RuntimeWarning
        )
        return True


# =============================================================================
# AI Configuration (LLM ë° ê²€ìƒ‰)
# =============================================================================
AI_CONFIG = {
    # LLM í”„ë¡œë°”ì´ë”
    "llm_provider": os.getenv("LLM_PROVIDER", "openai"),  # openai, gemini, azure

    # API Keys
    "openai_api_key": os.getenv("OPENAI_API_KEY"),
    "google_api_key": os.getenv("GOOGLE_API_KEY"),
    "azure_api_key": os.getenv("AZURE_API_KEY"),
    "azure_api_base": os.getenv("AZURE_API_BASE"),
    "azure_api_version": os.getenv("AZURE_API_VERSION"),

    # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
    "default_model": os.getenv("DEFAULT_LLM_MODEL", "gpt-4o"),

    # ê²€ìƒ‰ ì„¤ì •
    "retrieval_top_k": int(os.getenv("RETRIEVAL_TOP_K", "5")),
    "retrieval_min_score": float(os.getenv("RETRIEVAL_MIN_SCORE", "0.5")),

    # Encoder API Type (ë ˆê±°ì‹œ í˜¸í™˜)
    "encoder_api_type": os.getenv("ENCODER_API_TYPE", "openai"),
}


# =============================================================================
# DART API Configuration
# =============================================================================
DART_CONFIG = {
    "api_key": os.getenv("DART_API_KEY"),

    # ë³´ê³ ì„œ ê²€ìƒ‰ ì„¤ì •
    "search_start_date": os.getenv("DART_SEARCH_START_DATE", "20240101"),
    "report_type_code": "a001",  # ì‚¬ì—…ë³´ê³ ì„œ
    "page_count": 100,
    "page_delay_sec": 0.5,
    "max_search_days": 90,
}


# =============================================================================
# Batch Processing Configuration (Ingestionìš©)
# =============================================================================
BATCH_CONFIG = {
    "batch_size": int(os.getenv("BATCH_SIZE", "50")),
    "batch_delay_sec": int(os.getenv("BATCH_DELAY_SEC", "3")),
    "request_delay_sec": float(os.getenv("REQUEST_DELAY_SEC", "0.1")),
    "max_retries": int(os.getenv("MAX_RETRIES", "3")),
    "retry_delay_sec": int(os.getenv("RETRY_DELAY_SEC", "5")),
}


# =============================================================================
# Chunk Configuration (í…ìŠ¤íŠ¸ ì²­í‚¹)
# =============================================================================
CHUNK_CONFIG = {
    "max_chunk_size": int(os.getenv("MAX_CHUNK_SIZE", "2000")),
    "overlap": int(os.getenv("CHUNK_OVERLAP", "200")),
    "min_chunk_size": int(os.getenv("MIN_CHUNK_SIZE", "100")),
}


# =============================================================================
# Target Sections (DART ë³´ê³ ì„œ)
# =============================================================================
TARGET_SECTIONS = [
    "íšŒì‚¬ì˜ ê°œìš”",
    "ì‚¬ì—…ì˜ ë‚´ìš©",
    "ì¬ë¬´ì— ê´€í•œ ì‚¬í•­",
]


# =============================================================================
# Validation (í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ì²´í¬)
# =============================================================================
def validate_config(check_db=True, check_ai=False, check_dart=False):
    """
    ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬

    Args:
        check_db: DB ì ‘ì† ì •ë³´ ê²€ì¦
        check_ai: AI API í‚¤ ê²€ì¦
        check_dart: DART API í‚¤ ê²€ì¦

    Raises:
        RuntimeError: í•„ìˆ˜ ì„¤ì •ì´ ëˆ„ë½ëœ ê²½ìš°
    """
    missing = []

    if check_db:
        if not DB_CONFIG["password"]:
            missing.append("PG_PASSWORD (or DB_PASSWORD)")

    if check_ai:
        if AI_CONFIG["llm_provider"] == "openai" and not AI_CONFIG["openai_api_key"]:
            missing.append("OPENAI_API_KEY")
        elif AI_CONFIG["llm_provider"] == "gemini" and not AI_CONFIG["google_api_key"]:
            missing.append("GOOGLE_API_KEY")

    if check_dart:
        if not DART_CONFIG["api_key"]:
            missing.append("DART_API_KEY")

    if missing:
        raise RuntimeError(
            f"Missing required environment variables: {', '.join(missing)}. "
            "Please set them in .env or as environment variables."
        )


# =============================================================================
# Debug: Print current config (ê°œë°œìš©)
# =============================================================================
def print_config():
    """í˜„ì¬ ì„¤ì • ì¶œë ¥ (ë””ë²„ê¹…ìš©)"""
    print("\n" + "=" * 60)
    print("ğŸ”§ Hypercurve Unified Configuration")
    print("=" * 60)

    print("\nğŸ“¦ Database:")
    print(f"   Host: {DB_CONFIG['host']}:{DB_CONFIG['port']}")
    print(f"   Database: {DB_CONFIG['database']}")
    print(f"   User: {DB_CONFIG['user']}")
    print(f"   Password: {'*' * len(DB_CONFIG['password']) if DB_CONFIG['password'] else 'NOT SET'}")

    print("\nğŸ§  Embedding:")
    print(f"   Provider: {EMBEDDING_CONFIG['provider']}")
    print(f"   Dimension: {EMBEDDING_CONFIG['dimension']}")
    if EMBEDDING_CONFIG['provider'] == 'huggingface':
        print(f"   Model: {EMBEDDING_CONFIG['hf_model']}")
    else:
        print(f"   Model: {EMBEDDING_CONFIG['openai_model']}")

    print("\nğŸ¤– AI:")
    print(f"   LLM Provider: {AI_CONFIG['llm_provider']}")
    print(f"   Default Model: {AI_CONFIG['default_model']}")
    print(f"   OpenAI Key: {'SET' if AI_CONFIG['openai_api_key'] else 'NOT SET'}")
    print(f"   Google Key: {'SET' if AI_CONFIG['google_api_key'] else 'NOT SET'}")

    print("\nğŸ“Š DART:")
    print(f"   API Key: {'SET' if DART_CONFIG['api_key'] else 'NOT SET'}")

    print("=" * 60 + "\n")


if __name__ == "__main__":
    print_config()

