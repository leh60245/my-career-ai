"""
í†µí•© ì„¤ì • ëª¨ë“ˆ (Unified Configuration)

AIì™€ Ingestion ì–‘ìª½ì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ì„¤ì •ì„ ì¤‘ì•™ ê´€ë¦¬í•©ë‹ˆë‹¤.
í™˜ê²½ë³€ìˆ˜ ë„¤ì´ë°ì„ í†µì¼í•˜ê³  ì¶©ëŒì„ ë°©ì§€í•©ë‹ˆë‹¤.

í™˜ê²½ë³€ìˆ˜ í‘œì¤€:
- DB: PG_HOST, PG_PORT, PG_USER, PG_PASSWORD, PG_DATABASE
- AI: OPENAI_API_KEY, GOOGLE_API_KEY, ENCODER_API_TYPE
- DART: DART_API_KEY
"""
import os
from pathlib import Path
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ .env ë¡œë“œ
_project_root = Path(__file__).parent.parent.parent
_env_path = _project_root / ".env"
if _env_path.exists():
    load_dotenv(_env_path)
else:
    load_dotenv()  # ê¸°ë³¸ .env ë¡œë“œ ì‹œë„

# =============================================================================
# Database Configuration (í†µí•©)
# =============================================================================
# í™˜ê²½ë³€ìˆ˜ í˜¸í™˜ì„±: PG_* (ì‹ ê·œ í‘œì¤€) ìš°ì„ , DB_* (ë ˆê±°ì‹œ) í´ë°±
DB_CONFIG = {
    "host": os.getenv("PG_HOST") or os.getenv("DB_HOST", "localhost"),
    "port": os.getenv("PG_PORT") or os.getenv("DB_PORT", "5432"),
    "user": os.getenv("PG_USER") or os.getenv("DB_USER", "postgres"),
    "password": os.getenv("PG_PASSWORD") or os.getenv("DB_PASSWORD"),
    "database": os.getenv("PG_DATABASE") or os.getenv("DB_NAME", "postgres"),
}

# =============================================================================
# Embedding Configuration (í†µí•© - ê°€ì¥ ì¤‘ìš”!)
# =============================================================================
# âš ï¸ ê²½ê³ : DB Vector Indexì™€ ë™ì¼í•œ ëª¨ë¸/ì°¨ì›ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤!
# HuggingFace(768D) â†” OpenAI(1536D) ë¶ˆì¼ì¹˜ ì‹œ ì‹œìŠ¤í…œ ì¦‰ì‹œ ì¤‘ë‹¨ë©ë‹ˆë‹¤.
#
# í”„ë¡œë°”ì´ë” ë³€ê²½ ì‹œ í•„ìˆ˜ ì‘ì—…:
# 1. ê¸°ì¡´ DBì˜ ëª¨ë“  ì„ë² ë”© ì‚­ì œ (UPDATE "Source_Materials" SET embedding = NULL)
# 2. pgvector ì¸ë±ìŠ¤ ì¬ìƒì„±
# 3. ì „ì²´ ë°ì´í„° ì¬ì„ë² ë”© (python -m scripts.run_ingestion --embed --force)

# ============== í™œì„± ëª¨ë¸ ì„¤ì • (ëŸ°íƒ€ì„ ì¤‘ í•˜ë‚˜ë§Œ í™œì„±í™”) ==============
ACTIVE_EMBEDDING_PROVIDER = os.getenv("EMBEDDING_PROVIDER", "huggingface")

# í—ˆìš©ëœ í”„ë¡œë°”ì´ë” ëª©ë¡
_ALLOWED_PROVIDERS = ["huggingface", "openai"]

if ACTIVE_EMBEDDING_PROVIDER not in _ALLOWED_PROVIDERS:
    raise RuntimeError(
        f"Invalid EMBEDDING_PROVIDER: {ACTIVE_EMBEDDING_PROVIDER}. "
        f"Allowed values: {', '.join(_ALLOWED_PROVIDERS)}"
    )

# ============== í”„ë¡œë°”ì´ë”ë³„ ì„¤ì • ==============
EMBEDDING_CONFIG = {
    # í™œì„± í”„ë¡œë°”ì´ë” (ëŸ°íƒ€ì„ ì¤‘ ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€!)
    "provider": ACTIVE_EMBEDDING_PROVIDER,

    # HuggingFace ì„¤ì • (768ì°¨ì› - ë‹¤êµ­ì–´ ì§€ì›)
    "hf_model": os.getenv(
        "HF_EMBEDDING_MODEL",
        "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
    ),
    "hf_dimension": 768,

    # OpenAI ì„¤ì • (1536ì°¨ì› - ë†’ì€ ì •í™•ë„, ë¹„ìš© ë°œìƒ)
    "openai_model": os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small"),
    "openai_dimension": 1536,

    # ê³µí†µ ì„¤ì •
    "batch_size": int(os.getenv("EMBEDDING_BATCH_SIZE", "32")),
    "max_length": int(os.getenv("EMBEDDING_MAX_LENGTH", "512")),
}

# ============== í™œì„± ì°¨ì› ìë™ ê²°ì • ==============
if ACTIVE_EMBEDDING_PROVIDER == "openai":
    EMBEDDING_CONFIG["dimension"] = EMBEDDING_CONFIG["openai_dimension"]
    EMBEDDING_CONFIG["model_name"] = EMBEDDING_CONFIG["openai_model"]
else:  # huggingface
    EMBEDDING_CONFIG["dimension"] = EMBEDDING_CONFIG["hf_dimension"]
    EMBEDDING_CONFIG["model_name"] = EMBEDDING_CONFIG["hf_model"]


# ============== ëŸ°íƒ€ì„ ê²€ì¦ (ì°¨ì› ë¶ˆì¼ì¹˜ ì¡°ê¸° ê°ì§€) ==============
def validate_embedding_dimension_compatibility():
    """
    [ìˆ˜ì •ë¨] ì‚¬ìš©ì í™•ì¸ ì™„ë£Œ: ì‹¤ì œ ë°ì´í„°ëŠ” 768ì°¨ì›ì´ ë§ìŒ.
    ì§„ë‹¨ ë¡œì§ ì˜¤ë¥˜ë¡œ íŒë‹¨ë˜ì–´ ê²€ì¦ì„ ìƒëµí•˜ê³  ë¬´ì¡°ê±´ True ë°˜í™˜.
    """
    return True


# =============================================================================
# AI Configuration (LLM ë° ê²€ìƒ‰)
# =============================================================================
AI_CONFIG = {
    # LLM í”„ë¡œë°”ì´ë”
    "llm_provider": os.getenv("LLM_PROVIDER", "openai"),  # openai, gemini, azure

    # API Keys
    "openai_api_key": os.getenv("OPENAI_API_KEY"),
    "google_api_key": os.getenv("GOOGLE_API_KEY"),
    "azure_api_key": os.getenv("AZURE_API_KEY"),
    "azure_api_base": os.getenv("AZURE_API_BASE"),
    "azure_api_version": os.getenv("AZURE_API_VERSION"),

    # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
    "default_model": os.getenv("DEFAULT_LLM_MODEL", "gpt-4o"),

    # ê²€ìƒ‰ ì„¤ì •
    "retrieval_top_k": int(os.getenv("RETRIEVAL_TOP_K", "5")),
    "retrieval_min_score": float(os.getenv("RETRIEVAL_MIN_SCORE", "0.5")),

    # Encoder API Type (ë ˆê±°ì‹œ í˜¸í™˜)
    "encoder_api_type": os.getenv("ENCODER_API_TYPE", "openai"),
}

# =============================================================================
# DART API Configuration
# =============================================================================
DART_CONFIG = {
    "api_key": os.getenv("DART_API_KEY"),

    # ë³´ê³ ì„œ ê²€ìƒ‰ ì„¤ì •
    "search_start_date": os.getenv("DART_SEARCH_START_DATE", "20240101"),
    "report_type_code": "a001",  # ì‚¬ì—…ë³´ê³ ì„œ
    "page_count": 100,
    "page_delay_sec": 0.5,
    "max_search_days": 90,
}

# =============================================================================
# Batch Processing Configuration (Ingestionìš©)
# =============================================================================
BATCH_CONFIG = {
    "batch_size": int(os.getenv("BATCH_SIZE", "50")),
    "batch_delay_sec": int(os.getenv("BATCH_DELAY_SEC", "3")),
    "request_delay_sec": float(os.getenv("REQUEST_DELAY_SEC", "0.1")),
    "max_retries": int(os.getenv("MAX_RETRIES", "3")),
    "retry_delay_sec": int(os.getenv("RETRY_DELAY_SEC", "5")),
}

# =============================================================================
# Chunk Configuration (í…ìŠ¤íŠ¸ ì²­í‚¹)
# =============================================================================
CHUNK_CONFIG = {
    "max_chunk_size": int(os.getenv("MAX_CHUNK_SIZE", "2000")),
    "overlap": int(os.getenv("CHUNK_OVERLAP", "200")),
    "min_chunk_size": int(os.getenv("MIN_CHUNK_SIZE", "100")),
}

# =============================================================================
# Target Sections (DART ë³´ê³ ì„œ)
# =============================================================================
TARGET_SECTIONS = [
    "íšŒì‚¬ì˜ ê°œìš”",
    "ì‚¬ì—…ì˜ ë‚´ìš©",
    "ì¬ë¬´ì— ê´€í•œ ì‚¬í•­",
]

# =============================================================================
# Company Aliases (ê¸°ì—…ëª… ë³„ì¹­ - ê²€ìƒ‰ í•„í„°ë§ ë° Cross-Reference ê°ì§€ìš©)
# =============================================================================
# ì •ê·œí™”ëœ ê¸°ì—…ëª…(Key)ê³¼ í•´ë‹¹ ê¸°ì—…ì˜ ì•Œë ¤ì§„ ë³„ì¹­ë“¤(Value List)
# AI íŒŒíŠ¸: ê²€ìƒ‰ ì‹œ company_name í•„í„°ë§ì— ì‚¬ìš©
# DB íŒŒíŠ¸: Cross-Reference ë…¸ì´ì¦ˆ ì œê±° ì‹œ ì‚¬ìš©
COMPANY_ALIASES = {
    "ì‚¼ì„±ì „ì": ["ì‚¼ì „", "Samsung Electronics", "Samsung", "ì‚¼ì„±ì „ìãˆœ", "SAMSUNG"],
    "SKí•˜ì´ë‹‰ìŠ¤": ["í•˜ì´ë‹‰ìŠ¤", "SK Hynix", "Hynix", "ì—ìŠ¤ì¼€ì´í•˜ì´ë‹‰ìŠ¤", "SKí•˜ì´ë‹‰ìŠ¤ãˆœ"],
    "NAVER": ["ë„¤ì´ë²„", "Naver", "NHN", "ë„¤ì´ë²„ãˆœ"],
    "ì¹´ì¹´ì˜¤": ["Kakao", "ë‹¤ìŒì¹´ì¹´ì˜¤", "ì¹´ì¹´ì˜¤ãˆœ"],
    "LGì „ì": ["LG Electronics", "ì—˜ì§€ì „ì", "LGì „ìãˆœ", "ì—˜ì¥ì „ì"],
    "í˜„ëŒ€ìë™ì°¨": ["í˜„ëŒ€ì°¨", "Hyundai Motor", "í˜„ëŒ€ìë™ì°¨ãˆœ", "í˜„ì°¨"],
    "ê¸°ì•„": ["ê¸°ì•„ìë™ì°¨", "Kia", "KIA", "ê¸°ì•„ãˆœ"],
    "í¬ìŠ¤ì½”í™€ë”©ìŠ¤": ["í¬ìŠ¤ì½”", "POSCO", "í¬í•­ì œì² "],
    "ì…€íŠ¸ë¦¬ì˜¨": ["Celltrion", "ì…€íŠ¸ë¦¬ì˜¨ãˆœ"],
    "KBê¸ˆìœµ": ["KBê¸ˆìœµì§€ì£¼", "KB Financial", "êµ­ë¯¼ì€í–‰"],
}


def get_canonical_company_name(name: str) -> str:
    """
    ê¸°ì—…ëª… ë˜ëŠ” ë³„ì¹­ì„ ì •ê·œí™”ëœ ê¸°ì—…ëª…ìœ¼ë¡œ ë³€í™˜

    Args:
        name: ê²€ìƒ‰í•  ê¸°ì—…ëª… ë˜ëŠ” ë³„ì¹­

    Returns:
        ì •ê·œí™”ëœ ê¸°ì—…ëª… (ì°¾ì§€ ëª»í•˜ë©´ ì›ë³¸ ë°˜í™˜)

    Example:
        >>> get_canonical_company_name("ì‚¼ì „")
        "ì‚¼ì„±ì „ì"
        >>> get_canonical_company_name("SK Hynix")
        "SKí•˜ì´ë‹‰ìŠ¤"
    """
    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì •ê·œëª…ì´ ìˆìœ¼ë©´ ë°˜í™˜
    if name in COMPANY_ALIASES:
        return name

    # ë³„ì¹­ì—ì„œ ê²€ìƒ‰
    for canonical, aliases in COMPANY_ALIASES.items():
        if name in aliases:
            return canonical

    # ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ê²€ìƒ‰
    name_lower = name.lower().strip()
    for canonical, aliases in COMPANY_ALIASES.items():
        if canonical.lower() == name_lower:
            return canonical
        for alias in aliases:
            if alias.lower() == name_lower:
                return canonical

    return name  # ì°¾ì§€ ëª»í•˜ë©´ ì›ë³¸ ë°˜í™˜


def get_all_aliases(company_name: str) -> list:
    """
    íŠ¹ì • ê¸°ì—…ì˜ ëª¨ë“  ë³„ì¹­ ë°˜í™˜ (ì •ê·œëª… í¬í•¨)

    Args:
        company_name: ê¸°ì—…ëª… (ì •ê·œëª… ë˜ëŠ” ë³„ì¹­)

    Returns:
        í•´ë‹¹ ê¸°ì—…ì˜ ëª¨ë“  ì•Œë ¤ì§„ ì´ë¦„ ë¦¬ìŠ¤íŠ¸

    Example:
        >>> get_all_aliases("ì‚¼ì„±ì „ì")
        ["ì‚¼ì„±ì „ì", "ì‚¼ì „", "Samsung Electronics", ...]
    """
    canonical = get_canonical_company_name(company_name)
    if canonical in COMPANY_ALIASES:
        return [canonical] + COMPANY_ALIASES[canonical]
    return [company_name]


# =============================================================================
# Query Routing Keywords (ë¹„êµ ì§ˆë¬¸ ê°ì§€ìš©)
# =============================================================================
# ì´ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì§ˆë¬¸ì€ company_filterë¥¼ í™•ì¥(Expansion)í•˜ì—¬
# ì—¬ëŸ¬ ê¸°ì—…ì˜ ë°ì´í„°ë¥¼ ë™ì‹œì— ê²€ìƒ‰í•©ë‹ˆë‹¤.
COMPARISON_KEYWORDS = [
    "ë¹„êµ",
    "vs",
    "VS",
    "ëŒ€ë¹„",
    "ê²½ìŸ",
    "ê²½ìŸì‚¬",
    "ì—…ê³„",
    "ì‹œì¥ ì ìœ ìœ¨",
    "ìˆœìœ„",
    "ë­í‚¹",
]


def is_comparison_query(query: str) -> bool:
    """
    ì§ˆë¬¸ì´ ë¹„êµ/ê²½ìŸ ë¶„ì„ì„ ìš”ì²­í•˜ëŠ”ì§€ íŒë‹¨

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸

    Returns:
        True if ë¹„êµ ì§ˆë¬¸, False otherwise
    """
    return any(keyword in query for keyword in COMPARISON_KEYWORDS)


def extract_companies_from_query(query: str) -> list:
    """
    ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰ëœ ê¸°ì—…ëª…ë“¤ì„ ì¶”ì¶œí•˜ì—¬ ì •ê·œëª…ìœ¼ë¡œ ë°˜í™˜

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸

    Returns:
        ì§ˆë¬¸ì—ì„œ ë°œê²¬ëœ ê¸°ì—…ë“¤ì˜ ì •ê·œëª… ë¦¬ìŠ¤íŠ¸

    Example:
        >>> extract_companies_from_query("ì‚¼ì„±ì „ìì™€ í•˜ì´ë‹‰ìŠ¤ ë¹„êµí•´ì¤˜")
        ["ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"]
    """
    found_companies = set()

    for canonical, aliases in COMPANY_ALIASES.items():
        # ì •ê·œëª… ê²€ìƒ‰
        if canonical in query:
            found_companies.add(canonical)
            continue

        # ë³„ì¹­ ê²€ìƒ‰
        for alias in aliases:
            if alias in query:
                found_companies.add(canonical)
                break

    return list(found_companies)


# =============================================================================
# Validation (í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ì²´í¬)
# =============================================================================
def validate_config(check_db=True, check_ai=False, check_dart=False):
    """
    ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬

    Args:
        check_db: DB ì ‘ì† ì •ë³´ ê²€ì¦
        check_ai: AI API í‚¤ ê²€ì¦
        check_dart: DART API í‚¤ ê²€ì¦

    Raises:
        RuntimeError: í•„ìˆ˜ ì„¤ì •ì´ ëˆ„ë½ëœ ê²½ìš°
    """
    missing = []

    if check_db:
        if not DB_CONFIG["password"]:
            missing.append("PG_PASSWORD (or DB_PASSWORD)")

    if check_ai:
        if AI_CONFIG["llm_provider"] == "openai" and not AI_CONFIG["openai_api_key"]:
            missing.append("OPENAI_API_KEY")
        elif AI_CONFIG["llm_provider"] == "gemini" and not AI_CONFIG["google_api_key"]:
            missing.append("GOOGLE_API_KEY")

    if check_dart:
        if not DART_CONFIG["api_key"]:
            missing.append("DART_API_KEY")

    if missing:
        raise RuntimeError(
            f"Missing required environment variables: {', '.join(missing)}. "
            "Please set them in .env or as environment variables."
        )


# =============================================================================
# Debug: Print current config (ê°œë°œìš©)
# =============================================================================
def print_config():
    """í˜„ì¬ ì„¤ì • ì¶œë ¥ (ë””ë²„ê¹…ìš©)"""
    print("\n" + "=" * 60)
    print("ğŸ”§ Hypercurve Unified Configuration")
    print("=" * 60)

    print("\nğŸ“¦ Database:")
    print(f"   Host: {DB_CONFIG['host']}:{DB_CONFIG['port']}")
    print(f"   Database: {DB_CONFIG['database']}")
    print(f"   User: {DB_CONFIG['user']}")
    print(f"   Password: {'*' * len(DB_CONFIG['password']) if DB_CONFIG['password'] else 'NOT SET'}")

    print("\nğŸ§  Embedding:")
    print(f"   Provider: {EMBEDDING_CONFIG['provider']}")
    print(f"   Dimension: {EMBEDDING_CONFIG['dimension']}")
    if EMBEDDING_CONFIG['provider'] == 'huggingface':
        print(f"   Model: {EMBEDDING_CONFIG['hf_model']}")
    else:
        print(f"   Model: {EMBEDDING_CONFIG['openai_model']}")

    print("\nğŸ¤– AI:")
    print(f"   LLM Provider: {AI_CONFIG['llm_provider']}")
    print(f"   Default Model: {AI_CONFIG['default_model']}")
    print(f"   OpenAI Key: {'SET' if AI_CONFIG['openai_api_key'] else 'NOT SET'}")
    print(f"   Google Key: {'SET' if AI_CONFIG['google_api_key'] else 'NOT SET'}")

    print("\nğŸ“Š DART:")
    print(f"   API Key: {'SET' if DART_CONFIG['api_key'] else 'NOT SET'}")

    print("=" * 60 + "\n")


if __name__ == "__main__":
    print_config()
