#!/usr/bin/env python
"""
Enterprise STORM CLI - ê¸°ì—… ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±ê¸° (v4.0 - Pipeline Integrated)

Role:
    - ì‚¬ìš©ì ì…ë ¥ì„ ë°›ëŠ” CLI ì§„ì…ì  (Entry Point)
    - ReportJob ìƒì„± (PENDING)
    - src.engine.storm_pipeline ì‹¤í–‰ (Orchestrator í˜¸ì¶œ)

Changes:
    - ëª¨ë“  ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì œê±° -> src/engine/storm_pipeline.pyë¡œ ìœ„ì„
    - DB ì—°ê²° ë° Job ìƒì„± ë¡œì§ -> src/services/report_job_service.py ì‚¬ìš©
    - Thin Client êµ¬ì¡°ë¡œ ë³€ê²½

Usage:
    python scripts/run_storm.py
    python scripts/run_storm.py --company "ì‚¼ì„±ì „ì" --topic "AI ë°˜ë„ì²´ ì „ë§"
"""

import asyncio
import logging
import os
import sys
from argparse import ArgumentParser

from backend.src.common.config import AI_CONFIG, TOPICS
from backend.src.common.database.connection import AsyncDatabaseEngine, ensure_schema
from backend.src.common.enums import ReportJobStatus
from backend.src.company.engine.storm_pipeline import run_storm_pipeline
from backend.src.company.repositories.company_repository import CompanyRepository
from backend.src.company.repositories.report_job_repository import ReportJobRepository
from backend.src.company.services.report_job_service import ReportJobService


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
logger = logging.getLogger(__name__)


async def get_active_companies() -> list[tuple[int, str]]:
    """DBì—ì„œ í™œì„±í™”ëœ ê¸°ì—… ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    db = AsyncDatabaseEngine()
    async with db.get_session() as session:
        repo = CompanyRepository(session)
        # ëª¨ë“  ê¸°ì—…ì„ ê°€ì ¸ì˜¤ëŠ” ë©”ì„œë“œ ì‚¬ìš© (ì—†ìœ¼ë©´ ê¸°ë³¸ get_all ì‚¬ìš©)
        companies = await repo.get_all(limit=100, order_by="company_name")
        return [(c.id, c.company_name) for c in companies]


async def select_company_and_topic_interactive() -> tuple[int, str, str]:
    """
    CLI ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ: ê¸°ì—… ë° ì£¼ì œ ì„ íƒ
    """
    # 1. ê¸°ì—… ì„ íƒ
    companies = await get_active_companies()
    if not companies:
        logger.error("âŒ DBì— ë“±ë¡ëœ ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤. 'scripts/run_ingestion.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        sys.exit(1)

    print("\n" + "=" * 50)
    print("        [ Enterprise STORM ë¶„ì„ê¸° ]")
    print("=" * 50)
    print("\nğŸ¢ ë¶„ì„í•  ê¸°ì—…ì„ ì„ íƒí•˜ì„¸ìš”:")

    for idx, (cid, cname) in enumerate(companies):
        print(f"  [{cid}] {cname}")

    target_company = None
    while not target_company:
        try:
            sel = input("\nğŸ‘‰ ê¸°ì—… ID ì…ë ¥ (ìˆ«ì): ").strip()
            sel_id = int(sel)
            target_company = next((item for item in companies if item[0] == sel_id), None)
            if not target_company:
                print("[WARNING] ëª©ë¡ì— ì—†ëŠ” IDì…ë‹ˆë‹¤.")
        except ValueError:
            print("[WARNING] ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    # 2. ì£¼ì œ ì„ íƒ
    print(f"\nğŸ“ [{target_company[1]}] ê´€ë ¨ ë¶„ì„ ì£¼ì œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    for idx, topic_obj in enumerate(TOPICS):
        print(f"  [{idx + 1}] {topic_obj['label']}")

    # ë§ˆì§€ë§‰ ì˜µì…˜ìœ¼ë¡œ 'ììœ  ì£¼ì œ' ì¶”ê°€
    print(f"  [{len(TOPICS) + 1}] (ì§ì ‘ ì…ë ¥)")

    target_topic = ""
    while not target_topic:
        try:
            sel = input("\nğŸ‘‰ ì£¼ì œ ë²ˆí˜¸ ì…ë ¥: ").strip()
            idx = int(sel) - 1

            if 0 <= idx < len(TOPICS):
                target_topic = TOPICS[idx]["label"]
            elif idx == len(TOPICS):
                target_topic = input("   âœï¸  ì§ˆë¬¸í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            else:
                print("[WARNING] ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("[WARNING] ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    return target_company[0], target_company[1], target_topic


async def main():
    parser = ArgumentParser(description="Enterprise STORM CLI Executor")
    parser.add_argument("--company", type=str, help="ë¶„ì„í•  ê¸°ì—…ëª… (Interactive ëª¨ë“œ ìŠ¤í‚µ)")
    parser.add_argument("--topic", type=str, help="ë¶„ì„ ì£¼ì œ (Interactive ëª¨ë“œ ìŠ¤í‚µ)")
    parser.add_argument("--provider", type=str, default="openai", choices=["openai", "gemini"], help="LLM Provider")

    args = parser.parse_args()

    # 0. ê°œë°œ í¸ì˜: Alembic ì—†ì´ ìŠ¤í‚¤ë§ˆ ìƒì„±
    if os.getenv("AUTO_CREATE_SCHEMA") == "1":
        logger.warning("[WARNING] AUTO_CREATE_SCHEMA=1: Creating DB schema from models.")
        await ensure_schema()

    # 1. ì…ë ¥ê°’ ì²˜ë¦¬ (CLI Argument vs Interactive)
    if args.company and args.topic:
        # Argument ëª¨ë“œ: ê¸°ì—…ëª…ìœ¼ë¡œ ID ì¡°íšŒ í•„ìš”
        db = AsyncDatabaseEngine()
        async with db.get_session() as session:
            repo = CompanyRepository(session)
            comp_obj = await repo.get_by_company_name(args.company)
            if not comp_obj:
                logger.error(f"âŒ ê¸°ì—… '{args.company}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            company_id = comp_obj.id
            company_name = comp_obj.company_name
            topic = args.topic
    else:
        # Interactive ëª¨ë“œ
        company_id, company_name, topic = await select_company_and_topic_interactive()

    provider = args.provider
    logger.info(f"ğŸš€ ë¶„ì„ ì‹œì‘: {company_name} - {topic} (Model: {provider})")

    # 2. Job ìƒì„± (PENDING ìƒíƒœ)
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì „ì— DBì— 'ì‘ì—…ì´ ìƒì„±ë¨'ì„ ì•Œë¦½ë‹ˆë‹¤.
    db = AsyncDatabaseEngine()
    async with db.get_session() as session:
        job_repo = ReportJobRepository(session)
        job_service = ReportJobService(job_repo)

        job_id = await job_service.create_job(company_id=company_id, company_name=company_name, topic=topic)
        logger.info(f"ğŸ†” Job Created: {job_id}")

    # 3. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    # CLI í™˜ê²½ì´ë¯€ë¡œ ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ ë¡œì»¬ ë”•ì…”ë„ˆë¦¬ ìƒì„±
    # (API ì„œë²„ì—ì„œëŠ” ì´ê²Œ ì „ì—­ ë©”ëª¨ë¦¬ ë³€ìˆ˜ê°€ ë¨)
    jobs_dict = {job_id: {"status": ReportJobStatus.PENDING.value, "progress": 0, "message": "Initializing..."}}

    try:
        # [í•µì‹¬] ëª¨ë“  ë¡œì§ì€ ì—”ì§„ìœ¼ë¡œ ìœ„ì„
        await run_storm_pipeline(
            job_id=job_id, company_name=company_name, topic=topic, jobs_dict=jobs_dict, model_provider=provider
        )

        # ê²°ê³¼ í™•ì¸
        final_status = jobs_dict[job_id]
        if final_status["status"] == "COMPLETED":
            logger.info(f"âœ¨ ë¶„ì„ ì™„ë£Œ! Report ID: {final_status.get('report_id')}")
        else:
            logger.error(f"ğŸ”¥ ë¶„ì„ ì‹¤íŒ¨: {final_status.get('message')}")

    except KeyboardInterrupt:
        logger.warning("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        # ì¤‘ë‹¨ ì‹œ DB ìƒíƒœ ì—…ë°ì´íŠ¸ ë¡œì§ì´ í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì— ì¶”ê°€ (Service í˜¸ì¶œ)
    finally:
        await db.dispose()

    if AI_CONFIG.get("storm_force_exit"):
        logger.warning("[WARNING] STORM_FORCE_EXIT=1 is set. Exiting process now.")
        try:
            sys.exit(0)
        finally:
            os._exit(0)


if __name__ == "__main__":
    asyncio.run(main())
