import argparse
import asyncio
import logging
import os
import sys
from datetime import datetime, timedelta

from backend.src.common.database import AsyncDatabaseEngine
from backend.src.common.services.embedding import Embedding
from backend.src.company.repositories.analysis_report_repository import AnalysisReportRepository
from backend.src.company.repositories.company_repository import CompanyRepository
from backend.src.company.repositories.source_material_repository import SourceMaterialRepository
from backend.src.company.services.analysis_service import AnalysisService
from backend.src.company.services.company_service import CompanyService
from backend.src.company.services.dart_service import DartService
from backend.src.company.services.ingestion_service import IngestionService


# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(name)s: %(message)s", datefmt="%H:%M:%S")
logger = logging.getLogger("IngestionRunner")


async def process_corp_pipeline(
    session,
    corp_code: str,
    dart_svc: DartService,
    ingest_svc: IngestionService,
    comp_svc: CompanyService,
    anal_svc: AnalysisService,
) -> bool:
    """
    [ë‹¨ì¼ ê¸°ì—…(corp_code) ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸]
    """
    try:
        # 1. DARTì—ì„œ ìµœì‹  ê¸°ì—… ì •ë³´ ì¡°íšŒ (Live Data)
        corp_info = dart_svc.get_corp_by_code(corp_code)
        if not corp_info:
            logger.warning(f"   [WARNING] Invalid corp_code: {corp_code} (Not found in DART list)")
            return False

        dart_info = dart_svc.extract_company_info(corp_info)

        company_name = getattr(corp_info, "corp_name", "Unknown")

        logger.info(f"â–¶ï¸ Start Processing: {company_name} ({corp_code})")

        # 2. Company Onboarding (DB ë“±ë¡/í™•ì¸)
        company = await comp_svc.onboard_company(
            corp_code=dart_info["corp_code"],
            company_name=dart_info["company_name"],
            stock_code=dart_info["stock_code"],
            sector=dart_info["sector"],  # ì „ë‹¬
            product=dart_info["product"],  # ì „ë‹¬
        )

        # 3. Fetch Report (ìµœì‹  ì‚¬ì—…ë³´ê³ ì„œ ì¡°íšŒ)
        report = dart_svc.get_annual_report(corp_code=corp_code)
        if not report:
            logger.info(f"   â„¹ï¸ No annual report found for {company_name}")
            return False

        # 4. Save Report Metadata (ì¤‘ë³µ ì²´í¬ í¬í•¨)
        meta_data = dart_svc.extract_report_metadata(report, corp_info)

        # ì´ë¯¸ DBì— í•´ë‹¹ ì ‘ìˆ˜ë²ˆí˜¸(rcept_no)ì˜ ë³´ê³ ì„œê°€ ìˆë‹¤ë©´ -> Skip or Get Existing
        analysis_report = await anal_svc.save_report_metadata(
            company_id=company.id, data=meta_data, return_existing=True
        )

        # 5. Parse & Ingest Report Sections to Source Material
        raw_chunks = dart_svc.parse_report_sections(report)
        if not raw_chunks:
            logger.warning(f"   [WARNING] No valid sections parsed for {company_name}")
            return False

        saved_chunks = await ingest_svc.save_chunks(analysis_report.id, raw_chunks)

        logger.info(f"    Success: Ingested {len(saved_chunks)} chunks for {company_name}")
        return True

    except Exception as e:
        logger.error(f"   âŒ Failed processing {corp_code}: {str(e)}", exc_info=False)
        # ê°œë³„ ê¸°ì—… ì‹¤íŒ¨ëŠ” ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ë©ˆì¶”ì§€ ì•ŠìŒ (ë¡œê·¸ ë‚¨ê¸°ê³  False ë°˜í™˜)
        return False


async def run_pipeline(
    target_corps: list[str] | None = None,
    helper_stocks: list[str] | None = None,
    days: int = 90,
    limit: int | None = None,
):
    """
    [ë©”ì¸ ì‹¤í–‰ ë£¨í”„]
    - target_corpsê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë§Œ ì‹¤í–‰ (Manual Mode)
    - ì—†ìœ¼ë©´ ìµœê·¼ Nì¼ê°„ ë³´ê³ ì„œë¥¼ ë‚¸ ê¸°ì—… ìë™ ê²€ìƒ‰ (Auto/Efficient Mode)
    """

    # 1. ì¸í”„ë¼ ì´ˆê¸°í™”
    db_engine = AsyncDatabaseEngine()
    embedding = Embedding()
    dart_svc = DartService()

    logger.info("ğŸš€ Initializing Ingestion Pipeline...")

    # 2. íƒ€ê²Ÿ ë¦¬ìŠ¤íŠ¸ í™•ì • (Target Resolution)
    final_targets: list[str] = []  # List of corp_codes

    # [Case A] ëª…ì‹œì  corp_code ì§€ì •
    if target_corps:
        logger.info(f"ğŸ“‹ Mode: Manual (Explicit Corp Codes: {len(target_corps)})")
        final_targets.extend(target_corps)

    # [Case B] í¸ì˜ì„± stock_code ì§€ì • (Helper) -> corp_codeë¡œ ë³€í™˜
    if helper_stocks:
        logger.info(f"ğŸ“‹ Mode: Helper (Converting {len(helper_stocks)} stock codes...)")
        for stock in helper_stocks:
            corp = dart_svc.get_corp_by_stock_code(stock)
            if corp:
                final_targets.append(corp.corp_code)
            else:
                logger.warning(f"   [WARNING] Stock code not found: {stock}")

    # [Case C] ì•„ë¬´ê²ƒë„ ì§€ì • ì•ˆ í•¨ -> ìµœê·¼ ë³´ê³ ì„œ ì œì¶œ ê¸°ì—… ìë™ ê²€ìƒ‰ (Default)
    if not final_targets:
        start_date = (datetime.now() - timedelta(days=days)).strftime("%Y%m%d")
        logger.info(f"ğŸ“‹ Mode: Auto/Efficient (Reports since {start_date})")

        # DartServiceì—ì„œ "ìµœê·¼ ë³´ê³ ì„œê°€ ìˆëŠ” ê¸°ì—…ë“¤ì˜ corp_code"ë¥¼ ê°€ì ¸ì˜´
        # get_corps_with_reportsëŠ” (corp_obj) ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•œë‹¤ê³  ê°€ì •
        active_corps = dart_svc.get_corps_with_reports(bgn_de=start_date)

        final_targets = [c.corp_code for c in active_corps if hasattr(c, "corp_code")]
        logger.info(f"   Found {len(final_targets)} companies with recent reports.")

    # ì¤‘ë³µ ì œê±° (set)
    final_targets = list(set(final_targets))

    # Limit ì ìš©
    if limit and len(final_targets) > limit:
        logger.info(f"   Refining targets to first {limit} entries.")
        final_targets = final_targets[:limit]

    if not final_targets:
        logger.info("ğŸ›‘ No targets found. Exiting.")
        return

    # 3. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    stats = {"success": 0, "failed": 0, "skipped": 0}

    async with db_engine.get_session() as session:
        # Service Assembly (Dependency Injection)
        repo_material = SourceMaterialRepository(session)
        repo_company = CompanyRepository(session)
        repo_analysis = AnalysisReportRepository(session)

        ingest_svc = IngestionService(repo_material, embedding)
        comp_svc = CompanyService(repo_company)
        anal_svc = AnalysisService(repo_analysis, repo_company)

        logger.info(f"ğŸš€ Starting Batch for {len(final_targets)} companies...\n")

        for idx, corp_code in enumerate(final_targets):
            print(f"[{idx + 1}/{len(final_targets)}] Processing CorpCode: {corp_code}...")

            try:
                # ê¸°ì—… ë‹¨ìœ„ íŠ¸ëœì­ì…˜ ê²©ë¦¬
                async with session.begin_nested():
                    success = await process_corp_pipeline(session, corp_code, dart_svc, ingest_svc, comp_svc, anal_svc)

                    if success:
                        stats["success"] += 1
                    else:
                        stats["skipped"] += 1  # ì‹¤íŒ¨ê°€ ì•„ë‹ˆë¼, ë³´ê³ ì„œê°€ ì—†ê±°ë‚˜ ì´ë¯¸ ìˆì–´ì„œ ë„˜ì–´ê°„ ê²½ìš° ë“±

                await session.commit()

            except Exception as e:
                # ì—¬ê¸°ì„œ ì¡íˆëŠ” ê±´ process_corp_pipeline ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì‹¬ê°í•œ ì—ëŸ¬
                logger.error(f"ğŸ”¥ Critical Error on {corp_code}: {e}")
                stats["failed"] += 1
                # ë©”ì¸ ë£¨í”„ ê³„ì† ì§„í–‰

    # 4. ì¢…ë£Œ
    await db_engine.dispose()

    print("\n" + "=" * 50)
    print("ğŸ“Š Ingestion Summary")
    print(f"   Total Targets: {len(final_targets)}")
    print(f"   Success: {stats['success']}")
    print(f"   Skipped/No Report: {stats['skipped']}")
    print(f"   Failed : {stats['failed']}")
    print("=" * 50)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="DART Report Ingestion Pipeline")

    # Args êµ¬ì¡° ë³€ê²½
    parser.add_argument("--corps", nargs="+", help="Target specific Corp Codes (e.g., 00126380)")
    parser.add_argument("--stocks", nargs="+", help="Target specific Stock Codes (Helper, converted to Corp Code)")
    parser.add_argument("--days", type=int, default=90, help="Lookback days for Auto Mode (default: 90)")
    parser.add_argument("--limit", type=int, help="Max number of companies to process")

    args = parser.parse_args()

    try:
        asyncio.run(run_pipeline(target_corps=args.corps, helper_stocks=args.stocks, days=args.days, limit=args.limit))
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Pipeline stopped by user.")
