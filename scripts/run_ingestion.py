#!/usr/bin/env python
"""
ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (run_ingestion_v3.py)

PHASE 3.5: Legacy Migration Complete
- Refactored to call Async methods directly (No nested asyncio.run)
- Implements DB Reset using AsyncDatabaseEngine
- Orchestrates DART Agent -> DataPipeline -> EmbeddingWorker
"""

import argparse
import asyncio
import logging
import os
import sys

from sqlalchemy import func, select

# NEW: Service Layer & Database Engine
# ì—¬ê¸°ì— # noqa: E402ë¥¼ ë¶™ì—¬ì„œ ê²½ê³ ë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.
from src.database import AsyncDatabaseEngine

# Refactored Modules
from src.ingestion.embedding_worker import ContextLookbackEmbeddingWorker  # noqa: E402
from src.ingestion.pipeline import DataPipeline  # noqa: E402
from src.models import Base
from src.repositories import AnalysisReportRepository, CompanyRepository, SourceMaterialRepository

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)


# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


# ============================================================
# Helper Functions
# ============================================================


async def reset_database():
    """DB ì´ˆê¸°í™”: ëª¨ë“  í…Œì´ë¸” ì‚­ì œ í›„ ì¬ìƒì„±"""
    logger.warning("âš ï¸ RESETTING DATABASE: All data will be lost!")

    db_engine = AsyncDatabaseEngine()
    await db_engine.initialize()

    async with db_engine.engine.begin() as conn:
        # ì˜ì¡´ì„± ìˆœì„œì— ë”°ë¼ Drop (ë°˜ëŒ€ ìˆœì„œ ì•„ë‹˜, cascadeê°€ ì—†ìœ¼ë©´ ìˆœì„œ ì¤‘ìš”)
        # Base.metadata.drop_allì€ ìˆœì„œë¥¼ ì•Œì•„ì„œ ì²˜ë¦¬í•¨
        await conn.run_sync(Base.metadata.drop_all)
        logger.info("âœ… All tables dropped.")

        await conn.run_sync(Base.metadata.create_all)
        logger.info("âœ… All tables recreated.")

    await db_engine.dispose()


# ============================================================
# Async Execution Functions
# ============================================================


async def run_efficient_mode_async(
    reset_db: bool = False,
    limit: int | None = None,
    bgn_de: str | None = None,
    end_de: str | None = None,
):
    """
    íš¨ìœ¨ ëª¨ë“œ: ìµœê·¼ ì‚¬ì—…ë³´ê³ ì„œê°€ ìˆëŠ” ê¸°ì—…ë§Œ ì„ ë³„í•˜ì—¬ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    """
    if reset_db:
        await reset_database()

    logger.info("ğŸ”„ Efficient Mode: Searching for targets...")

    pipeline = DataPipeline()

    # 1. ëŒ€ìƒ ê¸°ì—… ê²€ìƒ‰ (Sync Agent call - It's okay in script level)
    # pipeline.run_efficient()ëŠ” ë‚´ë¶€ì—ì„œ asyncio.runì„ ì“°ë¯€ë¡œ ì‚¬ìš© ê¸ˆì§€
    # ì§ì ‘ Agentë¥¼ í†µí•´ íƒ€ê²Ÿì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    corps_with_reports = pipeline.agent.get_corps_with_reports(bgn_de=bgn_de, end_de=end_de)

    if limit:
        corps_with_reports = corps_with_reports[:limit]

    # (Corp, Report) íŠœí”Œì—ì„œ Corp ê°ì²´ë§Œ ì¶”ì¶œ
    targets = [item[0] for item in corps_with_reports]

    logger.info(f"ğŸ“‹ Found {len(targets)} targets with reports.")

    # 2. Async íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    await pipeline.run_pipeline_async(targets)

    logger.info("âœ… Efficient mode complete")


async def run_custom_mode_async(stock_codes: list, reset_db: bool = False):
    """
    ì»¤ìŠ¤í…€ ëª¨ë“œ: ì§€ì •í•œ ì¢…ëª©ì½”ë“œ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ì„œë§Œ ìˆ˜ì§‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    if reset_db:
        await reset_database()

    logger.info(f"ğŸ”„ Custom Mode: Processing stock codes: {stock_codes}")

    pipeline = DataPipeline()

    # 1. ì¢…ëª©ì½”ë“œë¡œ Corp ê°ì²´ ë³€í™˜
    targets = []
    for code in stock_codes:
        corp = pipeline.agent.get_corp_by_stock_code(code)
        if corp:
            targets.append(corp)
        else:
            logger.warning(f"âš ï¸ Stock code not found: {code}")

    if not targets:
        logger.error("âŒ No valid targets found.")
        return

    # 2. Async íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    await pipeline.run_pipeline_async(targets)

    logger.info("âœ… Custom mode complete")


async def run_embed_mode_async(batch_size: int = 32, limit: int | None = None, force: bool = False):
    """
    ì„ë² ë”© ìƒì„± ëª¨ë“œ: ìˆ˜ì§‘ëœ í…ìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ë²¡í„° ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    logger.info("ğŸ”„ Embedding Mode: Generating embeddings with context look-back...")

    worker = ContextLookbackEmbeddingWorker(batch_size=batch_size)

    # Async Run í˜¸ì¶œ
    await worker.run_async(limit=limit, force=force)

    logger.info("âœ… Embedding mode complete")


async def run_stats_mode_async():
    """
    DB í†µê³„ ì¡°íšŒ: í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì˜ ì ì¬ í˜„í™©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """
    logger.info("\n[STATS] DB Statistics")
    logger.info("=" * 40)

    db_engine = AsyncDatabaseEngine()

    async with db_engine.get_session() as session:
        company_repo = CompanyRepository(session)
        analysis_repo = AnalysisReportRepository(session)
        source_repo = SourceMaterialRepository(session)

        # 1. ê¸°ë³¸ ë ˆì½”ë“œ ì¹´ìš´íŠ¸
        companies_count = (await company_repo.count()) or 0
        reports_count = (await analysis_repo.count()) or 0

        # Source Material ì „ì²´ ì¹´ìš´íŠ¸
        # repo.count()ëŠ” í•„í„° ì—†ì´ ì „ì²´ ê°œìˆ˜
        materials_count = (await source_repo.count()) or 0

        # 2. ì„ë² ë”© ì™„ë£Œëœ ì²­í¬ ì¹´ìš´íŠ¸
        # ORMìœ¼ë¡œ ì¹´ìš´íŠ¸ ì¡°íšŒ
        stmt = select(func.count(source_repo.model.id)).where(source_repo.model.embedding.is_not(None))
        result = await session.execute(stmt)
        embedded_count = result.scalar() or 0

        # 3. ê²°ê³¼ ì¶œë ¥
        logger.info(f"   Companies       : {companies_count:,}")
        logger.info(f"   Reports         : {reports_count:,}")
        logger.info(f"   Source Materials: {materials_count:,}")
        logger.info(f"   Embedded chunks : {embedded_count:,}")

        if materials_count > 0:
            embed_rate = (embedded_count / materials_count) * 100
            logger.info(f"   Embedding Rate  : {embed_rate:.1f}%")
        else:
            logger.info("   Embedding Rate  : 0.0% (No materials)")

    await db_engine.dispose()
    logger.info("=" * 40)


# ============================================================
# Main Entry Point
# ============================================================


def main():
    parser = argparse.ArgumentParser(
        description="Enterprise STORM Data Ingestion Pipeline (v3.5 Async)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # Efficient mode (companies with reports)
    python -m scripts.run_ingestion_v3 --efficient
    
    # Specific companies
    python -m scripts.run_ingestion_v3 --codes 005930,000660
    
    # Generate embeddings
    python -m scripts.run_ingestion_v3 --embed --batch-size 64
    
    # DB statistics
    python -m scripts.run_ingestion_v3 --stats
""",
    )

    # ì‹¤í–‰ ëª¨ë“œ
    mode_group = parser.add_mutually_exclusive_group(required=True)
    mode_group.add_argument(
        "--efficient",
        action="store_true",
        help="Efficient mode (companies with reports)",
    )
    mode_group.add_argument("--codes", type=str, help="Stock codes (comma separated)")
    mode_group.add_argument("--embed", action="store_true", help="Embedding generation mode")
    mode_group.add_argument("--stats", action="store_true", help="DB statistics")

    # ê³µí†µ ì˜µì…˜
    parser.add_argument(
        "--reset-db",
        action="store_true",
        help="Reset DB before execution (WARNING: Deletes all data)",
    )
    parser.add_argument("--limit", type=int, help="Max companies/items to process")
    parser.add_argument("--bgn-de", type=str, help="Search start date (YYYYMMDD)")
    parser.add_argument("--end-de", type=str, help="Search end date (YYYYMMDD)")

    # ì„ë² ë”© ì˜µì…˜
    parser.add_argument("--batch-size", type=int, default=32, help="Embedding batch size")
    parser.add_argument("--force", action="store_true", help="Regenerate existing embeddings")

    args = parser.parse_args()

    # Asyncio ì‹¤í–‰ ë˜í¼
    if args.efficient:
        asyncio.run(
            run_efficient_mode_async(
                reset_db=args.reset_db,
                limit=args.limit,
                bgn_de=args.bgn_de,
                end_de=args.end_de,
            )
        )
    elif args.codes:
        stock_codes = [code.strip() for code in args.codes.split(",")]
        asyncio.run(run_custom_mode_async(stock_codes, reset_db=args.reset_db))
    elif args.embed:
        asyncio.run(run_embed_mode_async(batch_size=args.batch_size, limit=args.limit, force=args.force))
    elif args.stats:
        asyncio.run(run_stats_mode_async())


if __name__ == "__main__":
    main()
